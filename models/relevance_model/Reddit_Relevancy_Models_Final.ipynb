{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjlkvazwpEWKIi1JJtBkxY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-jk/SWB-GVCEH/blob/main/models/relevance_model/Reddit_Relevancy_Models_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Install and import necessary libraries"
      ],
      "metadata": {
        "id": "iym9EbbSCyNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mP3XCNlV0q7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b2e0d69-84f6-4d28-ab5d-bbeb0045c221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setfit in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: datasets>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (2.18.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from setfit) (2.5.1)\n",
            "Requirement already satisfied: evaluate>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (0.4.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from setfit) (0.20.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from setfit) (1.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from setfit) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (3.9.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.3.0->setfit) (6.0.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate>=0.3.0->setfit) (0.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->setfit) (4.10.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (2.1.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.1->setfit) (9.4.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->setfit) (3.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.3.0->setfit) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.3.0->setfit) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=2.2.1->setfit) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=2.2.1->setfit) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers>=2.2.1->setfit) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.3.0->setfit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.3.0->setfit) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets>=2.3.0->setfit) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.2.1->setfit) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install setfit\n",
        "!pip install tqdm\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import gdown\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Gr1D_v3v46JA",
        "outputId": "4b79cadc-5bb3-4ed0-bfd7-915fe4180392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Import the full Reddit dataset\n",
        "- remove duplicates to make sure that posts are unqiue\n",
        "- TitleText is the text column of interest"
      ],
      "metadata": {
        "id": "G_DVdEUwC3qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://drive.google.com/file/d/15reL84i-9niSW4Oa0_1oxR82-5UpAybo/view?usp=sharing\n",
        "\n",
        "\n",
        "# url = 'https://drive.google.com/uc?id=15reL84i-9niSW4Oa0_1oxR82-5UpAybo'\n",
        "# output_reddit_data = 'Complete_Data_v3.json'\n",
        "# gdown.download(url, output_reddit_data, quiet=False)\n",
        "\n",
        "file_path = '/content/drive/My Drive/SWB-GVCEH/Complete_Data_v3.json'\n",
        "reddit_data_df = pd.read_json(file_path)\n",
        "\n",
        "# with open(output_reddit_data, 'r') as f:\n",
        "#     reddit_data = json.load(f)\n",
        "\n",
        "# reddit_data_df = pd.DataFrame(reddit_data)\n",
        "print(f\"\\ncd_test shape: {reddit_data_df.shape}\")\n",
        "print(f\"\\n--------------- Columns: {reddit_data_df.columns}\")\n",
        "\n",
        "select_cols = ['Subreddit', 'Title', 'Text', 'TitleText']\n",
        "reddit_data_df = reddit_data_df[select_cols]\n",
        "reddit_data_df.drop_duplicates(inplace=True)\n",
        "reddit_data_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"\\n------------------------------\")\n",
        "print(reddit_data_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCHlgRt_4-Lt",
        "outputId": "694727ac-6598-4052-f319-9547ad31ae16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cd_test shape: (11160, 23)\n",
            "\n",
            "--------------- Columns: Index(['index', 'Subreddit', 'Title', 'Text', 'TitleText', 'relevance_score',\n",
            "       'most_common_centroid_id', 'top_terms_from_centroid',\n",
            "       'topics_from_centroid', 'Score_model2', 'label_model2', 'label_model1',\n",
            "       'relevant_sentences', 'topic_num', 'Relevant_document',\n",
            "       'Relevant_topic', 'topic_label', 'Sentiment_Full',\n",
            "       'Sentence_Level_Sentiment_Compund',\n",
            "       'Relevent_Sentence_Sentiment_Compund', 'BERT_sentiment_all',\n",
            "       'BERT_sentiments_relevant_sentences', 'manual_label'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Clone github repo to download twitter data\n",
        "- Twitter data will be used for the cosine similarity model"
      ],
      "metadata": {
        "id": "ByS7xcurDXkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ..\n",
        "!rm -rf SWB-GVCEH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8o_-3FiDkY-",
        "outputId": "6b539a6b-0d33-4b41-8ae0-2fc3ea901263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!apt-get install git\n",
        "!git config --global user.name \"alex-jk\"\n",
        "!git config --global user.email \"alex.joukova@gmail.com\"\n",
        "!git clone https://github.com/alex-jk/SWB-GVCEH.git\n",
        "%cd SWB-GVCEH\n",
        "\n",
        "import os\n",
        "os.environ['GITHUB_PAT'] = 'ghp_xxx'\n",
        "# Set your git remote URL to include the PAT for authentication\n",
        "repo_url = 'https://github.com/alex-jk/SWB-GVCEH.git'  # Replace with your repository's URL\n",
        "pat = os.environ['GITHUB_PAT']\n",
        "repo_url_with_token = repo_url[:8] + pat + \"@\" + repo_url[8:]\n",
        "\n",
        "!git remote set-url origin {repo_url_with_token}\n",
        "# Check the current remote URL\n",
        "!git remote -v"
      ],
      "metadata": {
        "id": "T25ygGTNEwrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of file names\n",
        "file_names = [\n",
        "    'GVCEH-tweets-combined_2023-02-08.csv',\n",
        "    'GVCEH-tweets-combined_2023-01-30.csv',\n",
        "    'GVCEH-tweets-combined_2023-01-21.csv',\n",
        "    'GVCEH-tweets-combined_2023-01-12.csv'\n",
        "]\n",
        "\n",
        "# Base URL for raw files in the GitHub repository\n",
        "base_url = 'https://raw.githubusercontent.com/alex-jk/SWB-GVCEH/main/data/processed/twitter/github_actions/'\n",
        "\n",
        "# Initialize a list to collect the DataFrames\n",
        "dfs = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    # Construct the full URL for the current file\n",
        "    file_url = base_url + file_name\n",
        "    # Read the CSV file\n",
        "    current_df = pd.read_csv(file_url)\n",
        "    # Append the DataFrame to the list\n",
        "    dfs.append(current_df)\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "tweets_combined_df = pd.concat(dfs, ignore_index=True)\n",
        "# Remove duplicates\n",
        "tweets_combined_df = tweets_combined_df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame\n",
        "print(tweets_combined_df.shape)\n",
        "print(tweets_combined_df.columns)\n",
        "print(tweets_combined_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ftdrq01JFWsO",
        "outputId": "6f0675ae-58cd-4a73-9004-4eb21c4a5262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5435, 17)\n",
            "Index(['Unnamed: 0', 'text', 'scrape_time', 'tweet_id', 'created_at',\n",
            "       'reply_count', 'quote_count', 'like_count', 'retweet_count',\n",
            "       'geo_full_name', 'geo_id', 'username', 'num_followers',\n",
            "       'search_keywords', 'search_neighbourhood', 'sentiment', 'score'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0                                               text  \\\n",
            "0           0  RT pressjournal: Colonsay islanders and people...   \n",
            "1           1  Colonsay islanders and people who have left th...   \n",
            "2           7  @ArianeBurgessHI Serviced plots for 25k are ex...   \n",
            "3           9  RT @VicBuilders: \"25-unit townhome development...   \n",
            "4          27  @OurNewHomecoach @laughatthemoon2 There is so ...   \n",
            "\n",
            "                  scrape_time             tweet_id                 created_at  \\\n",
            "0  2023-02-07 03:20:43.040309  1622564995115503616  2023-02-06 11:56:55+00:00   \n",
            "1  2023-02-07 03:20:43.040317  1622550741599625221  2023-02-06 11:00:16+00:00   \n",
            "2  2023-02-07 03:20:51.207543  1622549961081487360  2023-02-06 10:57:10+00:00   \n",
            "3  2023-02-07 03:20:56.511307  1622671505778778152  2023-02-06 19:00:09+00:00   \n",
            "4  2023-02-07 03:21:18.339644  1622767215811641344  2023-02-07 01:20:28+00:00   \n",
            "\n",
            "   reply_count  quote_count  like_count  retweet_count geo_full_name geo_id  \\\n",
            "0          0.0          0.0         0.0            0.0           NaN    NaN   \n",
            "1          0.0          0.0         0.0            0.0           NaN    NaN   \n",
            "2          0.0          0.0         1.0            0.0           NaN    NaN   \n",
            "3          0.0          0.0         0.0            0.0           NaN    NaN   \n",
            "4          0.0          0.0         1.0            0.0           NaN    NaN   \n",
            "\n",
            "          username  num_followers  \\\n",
            "0   elginnewsround            852   \n",
            "1     pressjournal          69944   \n",
            "2  ArianeBurgessHI           3207   \n",
            "3  DominiqueBandet             90   \n",
            "4   martin85468119             18   \n",
            "\n",
            "                                     search_keywords  \\\n",
            "0  (900-block pandora avenue OR esquimalt OR high...   \n",
            "1  (900-block pandora avenue OR esquimalt OR high...   \n",
            "2  (900-block pandora avenue OR esquimalt OR high...   \n",
            "3  (900-block pandora avenue OR esquimalt OR high...   \n",
            "4  (900-block pandora avenue OR esquimalt OR high...   \n",
            "\n",
            "                                search_neighbourhood sentiment     score  \n",
            "0  900-block pandora avenue OR esquimalt OR highl...  positive  0.351921  \n",
            "1  900-block pandora avenue OR esquimalt OR highl...  positive  0.344510  \n",
            "2  900-block pandora avenue OR esquimalt OR highl...  positive  0.339811  \n",
            "3  900-block pandora avenue OR esquimalt OR highl...  positive  0.365494  \n",
            "4  900-block pandora avenue OR esquimalt OR highl...  positive  0.363048  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Load pre-trained twitter relevancy model\n",
        "Check that tweets are considered relevant by the model\n",
        "- all tweets were found to be relevant by the model"
      ],
      "metadata": {
        "id": "wooByf-7Fhea"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u8zKTKkpFimn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}