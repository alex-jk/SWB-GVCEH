{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGvXilMXVQRcmWWUKLKD+J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alex-jk/SWB-GVCEH/blob/main/reddit_scraper/Unique_Search_Terms_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "chaCMp772BF-"
      },
      "outputs": [],
      "source": [
        "#!rm -rf /content/SWB-GVCEH  # Removes the entire SWB-GVCEH directory\n",
        "#!git clone https://github.com/alex-jk/SWB-GVCEH.git  # Clones the repository again"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "# Set your PAT here. Make sure to clear this cell's output or delete the PAT after setting the environment variable.\n",
        "os.environ['GITHUB_PAT'] = 'xxxx'  # Replace 'your_pat_here' with your actual PAT."
      ],
      "metadata": {
        "id": "MtPcWLd66zOA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw\n",
        "!pip install asyncpraw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8M56xzLexiK",
        "outputId": "7ab8ab84-af6c-4f2c-d7c3-a596db628c94"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.6.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2023.7.22)\n",
            "Requirement already satisfied: asyncpraw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: aiofiles<1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.8.0)\n",
            "Requirement already satisfied: aiohttp<4 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (3.8.6)\n",
            "Requirement already satisfied: aiosqlite<=0.17.0 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.17.0)\n",
            "Requirement already satisfied: asyncprawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (2.3.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from asyncpraw) (0.18.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4->asyncpraw) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<=0.17.0->asyncpraw) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from update-checker>=0.18->asyncpraw) (2.31.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.3.0->update-checker>=0.18->asyncpraw) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd SWB-GVCEH\n",
        "# !ls"
      ],
      "metadata": {
        "id": "SaFq-yQr2I3L"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"alex-jk\"\n",
        "!git config --global user.email \"alex.joukova@gmail.com\""
      ],
      "metadata": {
        "id": "R6v9Syii52ZK"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import praw\n",
        "import pandas as pd\n",
        "import asyncpraw\n",
        "import asyncio"
      ],
      "metadata": {
        "id": "9Ayih448e1QB"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of file names\n",
        "file_names = [\n",
        "    'GVCEH-2022-07-25-tweet-cleaned.csv',\n",
        "    'GVCEH-2022-07-18-tweet-cleaned.csv',\n",
        "    'GVCEH-2022-07-13-tweet-cleaned.csv',\n",
        "    'GVCEH-2022-07-12-tweet-cleaned.csv'\n",
        "]\n",
        "\n",
        "# Base URL for raw files in the GitHub repository\n",
        "base_url = 'https://raw.githubusercontent.com/alex-jk/SWB-GVCEH/main/data/cleaned/'\n",
        "\n",
        "# Initialize a list to collect the DataFrames\n",
        "dfs = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    # Construct the full URL for the current file\n",
        "    file_url = base_url + file_name\n",
        "    # Read the CSV file\n",
        "    current_df = pd.read_csv(file_url)\n",
        "    # Append the DataFrame to the list\n",
        "    dfs.append(current_df)\n",
        "\n",
        "# Concatenate all DataFrames in the list\n",
        "combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "# Remove duplicates\n",
        "combined_df = combined_df.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "# Displaying the first few rows of the DataFrame\n",
        "print(combined_df.shape)\n",
        "print(combined_df.columns)\n",
        "print(combined_df.head())\n",
        "#print(GVCEH_2022_07_25_tweet_cleaned['search_keywords'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIq7A2282urd",
        "outputId": "88bdadce-0f90-4874-ab2a-bf17b1ab1fd5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6268, 17)\n",
            "Index(['Unnamed: 0', 'text', 'scrape_time', 'tweet_id', 'created_at',\n",
            "       'reply_count', 'quote_count', 'like_count', 'retweet_count',\n",
            "       'geo_full_name', 'geo_id', 'geo_bbox', 'tweet_coordinate', 'username',\n",
            "       'num_followers', 'search_keywords', 'search_neighbourhood'],\n",
            "      dtype='object')\n",
            "   Unnamed: 0                                               text  \\\n",
            "0           4  “The black character entered mainstream postwa...   \n",
            "1           5  “The black character entered mainstream postwa...   \n",
            "2           8  @dizzyreader1 @SheldonTheCat07 I do think they...   \n",
            "3           9  @blue_heathen @InDecades @newsmax Of so, speci...   \n",
            "4          10  \"Come sleep, o sleep, the certain knot of peac...   \n",
            "\n",
            "                  scrape_time             tweet_id                 created_at  \\\n",
            "0  2022-07-25 10:50:38.621962  1550946480596426753  2022-07-23 20:50:30+00:00   \n",
            "1  2022-07-25 10:50:38.621962  1550938802469879811  2022-07-23 20:20:00+00:00   \n",
            "2  2022-07-25 10:50:40.099375  1551118966273212417  2022-07-24 08:15:54+00:00   \n",
            "3  2022-07-25 10:50:40.099375  1550913818385125377  2022-07-23 18:40:43+00:00   \n",
            "4  2022-07-25 10:50:40.099375  1550888278735278083  2022-07-23 16:59:14+00:00   \n",
            "\n",
            "   reply_count  quote_count  like_count  retweet_count geo_full_name geo_id  \\\n",
            "0            0            0           0              0           NaN    NaN   \n",
            "1            0            2          19              7           NaN    NaN   \n",
            "2            0            0           4              1           NaN    NaN   \n",
            "3            4            0           0              0           NaN    NaN   \n",
            "4            0            0           0              0           NaN    NaN   \n",
            "\n",
            "  geo_bbox tweet_coordinate         username  num_followers  \\\n",
            "0      NaN              NaN          ojalart           7326   \n",
            "1      NaN              NaN      parisreview        1006255   \n",
            "2      NaN              NaN  Mimithe20536023            226   \n",
            "3      NaN              NaN  TimeTravlPundit             89   \n",
            "4      NaN              NaN         SarbaniC            309   \n",
            "\n",
            "                                     search_keywords  \\\n",
            "0  (colwood OR sidney OR cook street village OR r...   \n",
            "1  (colwood OR sidney OR cook street village OR r...   \n",
            "2  (colwood OR sidney OR cook street village OR r...   \n",
            "3  (colwood OR sidney OR cook street village OR r...   \n",
            "4  (colwood OR sidney OR cook street village OR r...   \n",
            "\n",
            "                                search_neighbourhood  \n",
            "0  colwood OR sidney OR cook street village OR ro...  \n",
            "1  colwood OR sidney OR cook street village OR ro...  \n",
            "2  colwood OR sidney OR cook street village OR ro...  \n",
            "3  colwood OR sidney OR cook street village OR ro...  \n",
            "4  colwood OR sidney OR cook street village OR ro...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_search_terms(text):\n",
        "    # Remove any leading/trailing whitespace and the \"lang:en -is:retweet\" part\n",
        "    text = text.strip().rsplit(' lang:', 1)[0]\n",
        "\n",
        "    # Split the text on ' OR ' after removing brackets\n",
        "    terms = re.split(r'\\s+OR\\s+', re.sub(r'[()]', '', text))\n",
        "\n",
        "    return terms\n",
        "\n",
        "extracted_terms  = combined_df['search_keywords'].apply(extract_search_terms)\n",
        "print(extracted_terms .head())\n",
        "print(extracted_terms[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICwte61H3Vp2",
        "outputId": "c271fd61-b826-425e-94ae-43e65f55c5ef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [colwood, sidney, cook street village, rockhei...\n",
            "1    [colwood, sidney, cook street village, rockhei...\n",
            "2    [colwood, sidney, cook street village, rockhei...\n",
            "3    [colwood, sidney, cook street village, rockhei...\n",
            "4    [colwood, sidney, cook street village, rockhei...\n",
            "Name: search_keywords, dtype: object\n",
            "['colwood', 'sidney', 'cook street village', 'rockheights', 'hollywood park', 'songhees walkway', 'lekwungen', \"sc'ianew aceh\", 'city of langford', 'greater victoria housing society', 'peers victoria resources society', 'substance uvic', 'the victoria foundation', 'victoria chamber', 'workbc', 'people with lived experience', 'service provider', 'front line', 'poverty', 'tent', 'affordable', 'alcoholic', 'social problem']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Combine all lists into one\n",
        "all_terms = [term for sublist in extracted_terms for term in sublist]\n",
        "\n",
        "# Step 2: Extract unique terms\n",
        "unique_terms = list(set(term.replace('from:', '') for term in all_terms))\n",
        "unique_terms.sort()\n",
        "\n",
        "# Print or inspect the unique terms\n",
        "print(f\"Number of search terms: {len(unique_terms)}\")\n",
        "print(unique_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Npps4E4PHK",
        "outputId": "ee249081-6ed9-4eef-b8f4-f2bee56f49c4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of search terms: 587\n",
            "['#YYJ boys \"and\" girls club south vanouver island', '1upparents anawim house', '1upparents avi', '1upparents bc housing', '1upparents boys \"and\" girls club south vanouver island', '900-block pandora avenue', 'Greater Victoria Coalition to End Homelessness bc housing', 'Greater Victoria aceh', 'Greater Victoria aids vancouver island', 'Greater Victoria aryze developments', 'Greater Victoria avi', 'Greater Victoria bc housing', 'Greater Victoria beacon community services', 'Greater Victoria boys \"and\" girls club south vanouver island', 'Victoria B.C. aids vancouver island', 'Victoria B.C. anawim house', 'Victoria B.C. aryze developments', 'Victoria B.C. avi', 'Victoria B.C. bc housing', 'Victoria B.C. boys \"and\" girls club south vanouver island', 'Victoria aceh', 'Victoria aids vancouver island', 'Victoria anawim house', 'Victoria aryze developments', 'Victoria avi', 'Victoria bc housing', 'Victoria beacon community services', 'Victoria boys \"and\" girls club south vanouver island', 'Victoria burnside gorge neighbourhood association', 'Victoria the aboriginal coalition to end homelessness', 'VictoriaBC aceh', 'VictoriaBC aids vancouver island', 'VictoriaBC anawim house', 'VictoriaBC avi', 'VictoriaBC bc housing', 'VictoriaBC boys \"and\" girls club south vanouver island', 'VictoriaBC burnside gorge neighbourhood association', 'VictoriaBC the aboriginal coalition to end homelessness', 'YYJ aceh', 'YYJ aids vancouver island', 'YYJ anawim house', 'YYJ aryze developments', 'YYJ avi', 'YYJ bc housing', 'YYJ beacon community services', 'YYJ boys \"and\" girls club south vanouver island', 'YYJ burnside gorge neighbourhood association', 'YYJ the aboriginal coalition to end homelessness', 'acehsociety', 'adam_stirling aceh', 'adam_stirling aids vancouver island', 'adam_stirling anawim house', 'adam_stirling aryze developments', 'adam_stirling avi', 'adam_stirling bc housing', 'adam_stirling beacon community services', 'adam_stirling boys \"and\" girls club south vanouver island', 'adam_stirling burnside gorge neighbourhood association', 'adampolsen', 'addict', 'addicted', 'adriandix', 'affordable', 'affordable housing', 'alanrycroft anawim house', 'alanrycroft aryze developments', 'alanrycroft avi', 'alanrycroft bc housing', 'alanrycroft boys \"and\" girls club south vanouver island', 'alanrycroft burnside gorge neighbourhood association', 'alcoholic', 'anawimhouse aids vancouver island', 'anawimhouse bc housing', 'anawimhouse boys \"and\" girls club south vanouver island', 'avivanisle', 'barbdesjardins', 'barclaywallace', 'bc_housing', 'beacon hill park', 'beaconhillfolks', 'beaconsave', 'berniepauly', 'brucealready avi', 'buckleygkml', 'burnside-gorge', 'burnsidegorge aceh', 'burnsidegorge aids vancouver island', 'burnsidegorge aryze developments', 'burnsidegorge avi', 'burnsidegorge beacon community services', 'burnsidegorge burnside gorge neighbourhood association', 'camp', 'camper', 'camping', 'carolinaibarra', 'cbcnews aceh', 'cbcnews anawim house', 'cbcnews aryze developments', 'cbcnews avi', 'cbcnews bc housing', 'cbcnews beacon community services', 'cbcnews boys \"and\" girls club south vanouver island', 'cbcnews burnside gorge neighbourhood association', 'cbcnews the aboriginal coalition to end homelessness', 'cecelia ravine park', 'central park', 'cfax1070', 'charlesbodi', 'chartj88', 'chek_news', 'chiefmanak', 'city of colwood', 'city of langford', 'city of victoria', 'cityofvictoria', 'coast salish', 'colinplant2018', 'collude', 'collusion', 'colwood', 'community plan to end homelessness', 'complex care', 'cook street village', 'cool aid society', 'coordinated access \"and\" assessment', 'coreyranger', 'coryresilient', 'councllrntaylor', 'crd_bc', 'crime', 'cspc_victoria avi', 'cspc_victoria bc housing', 'cspc_victoria boys \"and\" girls club south vanouver island', 'cspoliceservice', 'ctess1', 'ctvnewsvi', 'darylbassett3', 'dave_eby', 'davidhscreech', 'district of north saanich', 'district of saanich', 'downtown victoria business association', 'drcvictoria', 'drug use', 'drugs', 'dvba', 'elizabethmay', 'emergency housing', 'encampment', 'eric_doherty', 'esquimalt', 'esquimaltbc', 'esquimaltnation', 'evict', 'evicted', 'eviction', 'existenceprojct', 'extremeoutreach', 'fairfield-gonzales', 'fairfield_comm', 'fernwood', 'fernwood community association', 'fernwoodfca', 'firstmetvic', 'foul bay', 'foundry victoria', 'foundryvictoria', 'front line', 'front line worker', 'frontline', 'frontline worker', 'galloping goose', 'goldstreamnews', 'gonzales', 'gonzales park', 'gracealore aceh', 'gracealore aids vancouver island', 'gracealore anawim house', 'gracealore aryze developments', 'gracealore avi', 'gracealore bc housing', 'gracealore beacon community services', 'gracealore boys \"and\" girls club south vanouver island', 'gracealore burnside gorge neighbourhood association', 'gracealore the aboriginal coalition to end homelessness', 'greater victoria acting together', 'greater victoria coalition to end homelessness', 'greater victoria housing society', 'habitat for humanity victoria', 'habitatvictoria', 'harm reduction', 'harris green', 'hattiecosta1', 'healthcare', 'hilarylmarks', 'hillside-quadra', 'hollywood park', 'homeforhope', 'homeless', 'homelessness', 'homelessness services association of bc', 'houseanawim', 'housesooke', 'housing', 'ilfp_victoria beacon community services', 'irving park', 'island health', 'islandcommha', 'jamesbaycp', 'jeremyloveday', 'jfatkey avi', 'jfatkey bc housing', 'johnhoward_can', 'juan de fuca', 'katstinson', 'kevinalbersbc aceh', 'kevinalbersbc aids vancouver island', 'kevinalbersbc avi', 'kevinalbersbc bc housing', 'kevinalbersbc boys \"and\" girls club south vanouver island', 'kristaloughton', 'kwakwaka’wakw', 'langford', 'laurel_bc', 'lekwungen', 'literacy victoria', 'lived experience', 'lochside', 'louise_hartland aceh', 'louise_hartland anawim house', 'louise_hartland aryze developments', 'louise_hartland avi', 'louise_hartland bc housing', 'louise_hartland burnside gorge neighbourhood association', 'low income', 'low-income', 'majatait', 'makola housing society', 'makolahousing', 'malahat aceh', 'malahat aids vancouver island', 'malahat anawim house', 'malahat aryze developments', 'malahat avi', 'malahat bc housing', 'malahat beacon community services', 'malahat boys \"and\" girls club south vanouver island', 'malahat burnside gorge neighbourhood association', 'malahat the aboriginal coalition to end homelessness', 'marikaalbert', 'mental health society of greater victoria', 'metchosin', 'mhrpsouthisland', 'mhsvictoria anawim house', 'mhsvictoria avi', 'mhsvictoria boys \"and\" girls club south vanouver island', 'millstream', 'murdochoakbay aceh', 'murdochoakbay anawim house', 'murdochoakbay aryze developments', 'murdochoakbay avi', 'murdochoakbay bc housing', 'murdochoakbay boys \"and\" girls club south vanouver island', 'murdochoakbay burnside gorge neighbourhood association', 'murdochoakbay the aboriginal coalition to end homelessness', 'murray_langdon', 'mustardseedvic anawim house', 'mustardseedvic avi', 'mustardseedvic bc housing', 'mustardseedvic burnside gorge neighbourhood association', 'mydvba', 'narcotics', 'need_2', 'nicolechaland', 'ninethreeseven', 'north park', 'nuu-chah-nulth', 'nuu-chah-nulth aceh', 'nuu-chah-nulth aids vancouver island', 'nuu-chah-nulth anawim house', 'nuu-chah-nulth aryze developments', 'nuu-chah-nulth avi', 'nuu-chah-nulth bc housing', 'nuu-chah-nulth beacon community services', 'nuu-chah-nulth boys \"and\" girls club south vanouver island', 'nuu-chah-nulth burnside gorge neighbourhood association', 'nuu-chah-nulth the aboriginal coalition to end homelessness', 'oak bay', 'oakbaynews', 'oaklands', 'oaklands park', 'ops', 'our place society', 'ourplacesociety', 'outreachsolid', 'overdose', 'overdosed', 'pacheedaht aceh', 'pacheedaht aids vancouver island', 'pacheedaht anawim house', 'pacheedaht aryze developments', 'pacheedaht avi', 'pacheedaht bc housing', 'pacheedaht beacon community services', 'pacheedaht boys \"and\" girls club south vanouver island', 'pacheedaht burnside gorge neighbourhood association', 'pacheedaht the aboriginal coalition to end homelessness', 'pacifica housing', 'pacificahousing', 'pacochran', 'pandora avenue', 'pauquachin aceh', 'pauquachin aids vancouver island', 'pauquachin anawim house', 'pauquachin aryze developments', 'pauquachin avi', 'pauquachin bc housing', 'pauquachin beacon community services', 'pauquachin boys \"and\" girls club south vanouver island', 'pauquachin burnside gorge neighbourhood association', 'peer housing support', 'peer housing support program', 'peers victoria resources society', 'peersvictoria', 'people with lived experience', 'person experiencing homelessness', 'photowarrior aceh', 'photowarrior aids vancouver island', 'photowarrior anawim house', 'photowarrior avi', 'photowarrior bc housing', 'photowarrior beacon community services', 'photowarrior boys \"and\" girls club south vanouver island', 'photowarrior the aboriginal coalition to end homelessness', 'pit', 'pit count', 'point ellice park', 'point in time', 'poor', 'poverty', 'povertypimps', 'quadra', 'quadra village', 'quadra village community centre', 'quadravillage', 'r_garrison', 'reaching home', 'red cedar café', 'rentsmart', 'rentsmartedu', 'restorative justice victoria', 'rock bay', 'rockheights', 'rockland', 'rotary club of victoria', 'royal athletic park', 'saanich', 'saanichnews', 'saanichpolice', 'saanichton', 'safe supply', 'safer victoria', 'safervic', 'safervic aceh', 'safervic bc housing', 'salarmyvicarc', 'salt spring island', 'saltspringx', 'salvation army victoria', 'sarahpottsvic aceh', 'sarahpottsvic aids vancouver island', 'sarahpottsvic anawim house', 'sarahpottsvic aryze developments', 'sarahpottsvic avi', 'sarahpottsvic bc housing', 'sarahpottsvic beacon community services', 'sarahpottsvic boys \"and\" girls club south vanouver island', 'sarahpottsvic burnside gorge neighbourhood association', 'sarahpottsvic the aboriginal coalition to end homelessness', \"sc'ianew aceh\", \"sc'ianew aids vancouver island\", \"sc'ianew anawim house\", \"sc'ianew aryze developments\", \"sc'ianew avi\", \"sc'ianew bc housing\", \"sc'ianew beacon community services\", 'sc\\'ianew boys \"and\" girls club south vanouver island', \"sc'ianew burnside gorge neighbourhood association\", \"sc'ianew the aboriginal coalition to end homelessness\", 'self_govern4us', 'selkirk green', 'selkirk trestle', 'service provider', 'shelliegudgeon', 'shelter', 'sidney', 'sjavicbc', 'soap4hopeyyj', 'social housing', 'social problem', 'social structure', 'solid outreach', 'songhees', 'songhees walkway', 'songheeschief', 'sooke', 'sooke homelessness coalition', 'sookecoalition', 'sookenews', 'south_island_c', 'spaynebc', 'spd_community', 'stadacona park', 'stephen_andrew', 'stolen', 'subsidized housing', 'substance use', 'substance uvic', 'substanceuvic', 'svdpvi', \"t'sou-ke aceh\", \"t'sou-ke aids vancouver island\", \"t'sou-ke anawim house\", \"t'sou-ke aryze developments\", \"t'sou-ke avi\", \"t'sou-ke bc housing\", \"t'sou-ke beacon community services\", 't\\'sou-ke boys \"and\" girls club south vanouver island', \"t'sou-ke burnside gorge neighbourhood association\", 'tagvictoriabc aceh', 'tagvictoriabc aids vancouver island', 'tagvictoriabc avi', 'tagvictoriabc bc housing', 'tagvictoriabc beacon community services', 'tagvictoriabc boys \"and\" girls club south vanouver island', 'tagvictoriabc burnside gorge neighbourhood association', 'tagvictoriabc the aboriginal coalition to end homelessness', 'talktoaryze', 'temporary shelter', 'tenant action group victoria', 'tent', 'the backpack project', 'the cridge centre for the family', 'the downtown victoria business association', 'the existence project', 'the gorge', 'the homeless ideas podcast', 'the john howard society of victoria', 'the mustard seed', 'the victoria foundation', 'the victoria real estate board', 'thebackpackpro1', 'thecridgecentre', 'theft', 'thief', 'timescolonist', 'togethervic', 'topaz park', 'tourismvi', 'town of view royal', 'township of esquimalt', 'tsartlip aceh', 'tsartlip aids vancouver island', 'tsartlip anawim house', 'tsartlip aryze developments', 'tsartlip avi', 'tsartlip bc housing', 'tsartlip beacon community services', 'tsartlip boys \"and\" girls club south vanouver island', 'tsartlip burnside gorge neighbourhood association', 'tsawout aceh', 'tsawout aids vancouver island', 'tsawout anawim house', 'tsawout aryze developments', 'tsawout avi', 'tsawout bc housing', 'tsawout beacon community services', 'tsawout boys \"and\" girls club south vanouver island', 'tsawout burnside gorge neighbourhood association', 'tsawout the aboriginal coalition to end homelessness', 'tseycum aceh', 'tseycum aids vancouver island', 'tseycum anawim house', 'tseycum aryze developments', 'tseycum avi', 'tseycum bc housing', 'tseycum beacon community services', 'tseycum boys \"and\" girls club south vanouver island', 'tseycum burnside gorge neighbourhood association', 'umbrella society', 'umbrellasociety', 'unhoused', 'united way southern vancouver island', 'unitedatoakbay', 'uplands', 'uvic aids vancouver island', 'uvic anawim house', 'uvic aryze developments', 'uvic avi', 'uvic beacon community services', 'vancouver island mental health society', 'vandupeople', 'vanislandhealth', 'varcsvictoria', 'vfamcourt aceh', 'vfamcourt avi', 'vfamcourt burnside gorge neighbourhood association', 'vibrant victoria', 'vic west', 'vic west park', 'viccoolaid', 'vicfoundation', 'vicpdcanada', 'vicplacemaking aceh', 'vicplacemaking aids vancouver island', 'vicplacemaking anawim house', 'vicplacemaking aryze developments', 'vicplacemaking avi', 'vicplacemaking bc housing', 'vicplacemaking beacon community services', 'vicplacemaking burnside gorge neighbourhood association', 'vicplacemaking the aboriginal coalition to end homelessness', 'victoria', 'victoria brain injury society', 'victoria chamber', 'victoria family court', 'victoria harbour cats', 'victoria native friendship centre', 'victoria placemaking', 'victoria ready', 'victoria real estate board', 'victoria sexual assault centre', 'victoria tenant action group', 'victoria west', 'victoria women in need', 'victoriabuzzes', 'victoriadra aceh', 'victoriadra bc housing', 'victoriadra the aboriginal coalition to end homelessness', 'victorianews aceh', 'victorianews aids vancouver island', 'victorianews anawim house', 'victorianews aryze developments', 'victorianews avi', 'victorianews bc housing', 'victorianews beacon community services', 'victorianews boys \"and\" girls club south vanouver island', 'victorianews burnside gorge neighbourhood association', 'victorianews the aboriginal coalition to end homelessness', 'victoriasandy', 'victoriavisitor aceh', 'victoriavisitor aids vancouver island', 'victoriavisitor burnside gorge neighbourhood association', 'victoriavisitor the aboriginal coalition to end homelessness', 'victoriaworkbc', 'victoriawth anawim house', 'vicyouthcouncil', 'view royal', 'violence', 'vreb', 'vreb aceh', 'vreb aids vancouver island', 'vreb anawim house', 'vreb avi', 'vreb bc housing', 'vreb beacon community services', 'vreb boys \"and\" girls club south vanouver island', 'wearenorthpark', 'west shore', 'workbc', 'workingupstream', 'wschamber1', 'wsáneć aceh', 'wsáneć aids vancouver island', 'wsáneć anawim house', 'wsáneć aryze developments', 'wsáneć avi', 'wsáneć bc housing', 'wsáneć beacon community services', 'wsáneć boys \"and\" girls club south vanouver island', 'wsáneć burnside gorge neighbourhood association', 'wsáneć the aboriginal coalition to end homelessness', 'youngparentssup', 'yyj_housing', 'yyjpolitics', 'zacdevries avi', 'zacdevries burnside gorge neighbourhood association']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Collect data from specific subreddits"
      ],
      "metadata": {
        "id": "sSRCCcXjb3j4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Connect to Reddit"
      ],
      "metadata": {
        "id": "8dA0PBv7f4Lv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the Reddit client\n",
        "user_agent=\"my_scraper:v1.0 (by /u/neuro-psych-amateur)\"\n",
        "client_id='syz99Sr36y8ZEAwMYMqa1A'\n",
        "client_secret='pWjCafggxLSgDkjUyospIJn_2w1oww'\n",
        "\n",
        "reddit = asyncpraw.Reddit(client_id=client_id,\n",
        "                     client_secret=client_secret,  # Insert your client_secret here\n",
        "                     user_agent=user_agent)  # This identifies your script to Reddit"
      ],
      "metadata": {
        "id": "63vr4R_MeZyX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Define relevant subreddits"
      ],
      "metadata": {
        "id": "paK3ZGiaf8A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subreddits_list = ['Sooke', 'VictoriaBC', 'gulfislands']"
      ],
      "metadata": {
        "id": "P8NkydWWb58H"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# async def fetch_data(reddit, subreddit_names, limit_num=5000):\n",
        "#     titles = []\n",
        "#     texts = []\n",
        "#     user_ids = []\n",
        "#     comments = []\n",
        "#     subreddits = []\n",
        "\n",
        "#     for subreddit_name in subreddit_names:\n",
        "#         print(f\"\\nFetching data from subreddit: {subreddit_name}\")\n",
        "#         subreddit = await reddit.subreddit(subreddit_name)\n",
        "\n",
        "#         submissions = []\n",
        "#         async for submission in subreddit.hot(limit=limit_num):  # You can change .hot to .new or .top if needed\n",
        "#             submissions.append(submission)\n",
        "#         print(f\"Found {len(submissions)} submissions in subreddit '{subreddit_name}'\")\n",
        "\n",
        "#         for submission in submissions:\n",
        "#             print(f\"Processing submission: {submission.id}\")\n",
        "#             await asyncio.sleep(1)  # Introduce a delay to respect rate limits\n",
        "#             await submission.load()\n",
        "#             comment_queue = submission.comments[:]\n",
        "\n",
        "#             comment_count = 0\n",
        "#             while comment_queue:\n",
        "#                 comment = comment_queue.pop(0)\n",
        "#                 if isinstance(comment, asyncpraw.models.Comment):\n",
        "#                     titles.append(submission.title)\n",
        "#                     texts.append(submission.selftext)\n",
        "#                     user_ids.append(submission.author.name if submission.author else None)\n",
        "#                     comments.append(comment.body)\n",
        "#                     subreddits.append(subreddit_name)\n",
        "#                     comment_count += 1\n",
        "#                 elif isinstance(comment, asyncpraw.models.MoreComments):\n",
        "#                     more_comments = await comment.comments()\n",
        "#                     comment_queue.extend(more_comments)\n",
        "\n",
        "#             print(f\"Appended {comment_count} comments for submission {submission.id}\")\n",
        "\n",
        "#     df = pd.DataFrame({\n",
        "#         'Subreddit': subreddits,\n",
        "#         'Title': titles,\n",
        "#         'Text': texts,\n",
        "#         'User ID': user_ids,\n",
        "#         'Comment': comments\n",
        "#     })\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "brNNjcsef2M2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# async def main():\n",
        "#     subreddits = ['Sooke', 'VictoriaBC', 'gulfislands']\n",
        "#     df = await fetch_data(reddit, subreddits)\n",
        "\n",
        "#     await reddit.close()\n",
        "#     return df\n",
        "\n",
        "# # Run the main function and get the dataframe\n",
        "# dataframe = await main()"
      ],
      "metadata": {
        "id": "rDwjWn4qiLMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(dataframe.shape)\n",
        "# print(dataframe.columns)\n",
        "# print(dataframe.head(50))\n",
        "\n",
        "# dataframe.to_csv('reddit_data.csv', index=False)"
      ],
      "metadata": {
        "id": "c8s0sUvbs2Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Define search terms"
      ],
      "metadata": {
        "id": "oLiOIQXrtRL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls /content/SWB-GVCEH/data"
      ],
      "metadata": {
        "id": "vssAOPE4tTnp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# uploaded = files.upload()"
      ],
      "metadata": {
        "id": "3jQ4vo8xw_VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !ls\n",
        "# !mv Reddit_Search_Terms.csv /content/SWB-GVCEH/data/Reddit_Search_Terms.csv"
      ],
      "metadata": {
        "id": "KieLXYiWxFSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your CSV file\n",
        "# file_path = '/content/SWB-GVCEH/data/Reddit_Search_Terms.csv'\n",
        "file_path = 'https://raw.githubusercontent.com/alex-jk/SWB-GVCEH/main/data/Reddit_Search_Terms.csv'\n",
        "# Load the CSV file into a DataFrame\n",
        "reddit_search_terms_df = pd.read_csv(file_path)\n",
        "# Display the first few rows of the DataFrame\n",
        "print(reddit_search_terms_df.head(15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AM2_zjIEyUz_",
        "outputId": "099c0855-5e0f-47af-aa2b-351d41d0d190"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                 search_term\n",
            "0                              #PovertyPimps\n",
            "1   Aboriginal Coalition to End Homelessness\n",
            "2                                       ACEH\n",
            "3                                     Addict\n",
            "4                                   Addicted\n",
            "5                                 Affordable\n",
            "6                         Affordable Housing\n",
            "7                        Affordable housing \n",
            "8                                 Alcoholic \n",
            "9                                     Anawim\n",
            "10                                BC Housing\n",
            "11                                      Camp\n",
            "12                                    Camper\n",
            "13                                   Camping\n",
            "14                                   Collude\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd\n",
        "# !ls\n",
        "# %cd /content\n",
        "# !ls\n",
        "# %cd /content/SWB-GVCEH"
      ],
      "metadata": {
        "id": "SLCP5Ojt1NJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from getpass import getpass\n",
        "# pat = getpass('Enter your PAT: ')"
      ],
      "metadata": {
        "id": "poVlJX5K5vgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git remote set-url origin https://alex-jk:{pat}@github.com/alex-jk/SWB-GVCEH.git"
      ],
      "metadata": {
        "id": "-1s8Bzg75-qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git add '/content/SWB-GVCEH/data/Reddit_Search_Terms.csv'\n",
        "# !git commit -m \"Added Reddit Search Terms list csv file\""
      ],
      "metadata": {
        "id": "nbDeKRzXyeV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git status\n",
        "# !git push origin main"
      ],
      "metadata": {
        "id": "Q4Zuzz7h0hDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_terms = reddit_search_terms_df['search_term'].tolist()\n",
        "search_terms = list( set( search_terms + unique_terms ))\n",
        "print(len(search_terms))\n",
        "print(search_terms)  # Print to verify"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4ZawADN0Ljx",
        "outputId": "b7d1288f-c1db-4e26-d8cd-cd18f09d4009"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679\n",
            "['north park', 'louise_hartland bc housing', 'cool aid society', 'drcvictoria', 'social problem', 'spd_community', 'substance use', 'photowarrior bc housing', 'adam_stirling aryze developments', 'burnside-gorge', 'mental health society of greater victoria', 'victorianews aceh', 'cbcnews anawim house', 'nuu-chah-nulth aceh', 'Greater Victoria beacon community services', 'quadra village', 'pacheedaht avi', 'YYJ beacon community services', 'pauquachin beacon community services', '1upparents anawim house', 'makola housing society', 'lochside', 'tseycum aids vancouver island', 'wsáneć bc housing', 'hollywood park', 'gracealore beacon community services', 'murdochoakbay aryze developments', 'sooke', 'VictoriaBC anawim house', 'tagvictoriabc bc housing', 'Victoria beacon community services', 'Lived Experience', 'tsawout beacon community services', \"t'sou-ke aids vancouver island\", \"Victoria Women's Transition House\", 'south_island_c', 'Sooke Homelessness Coalition', 'wsáneć avi', 'peers victoria resources society', 'cspc_victoria bc housing', 'tsawout bc housing', 'hillside-quadra', 'People with lived experience', 'Housing', 'victoria real estate board', 'person experiencing homelessness', 'tseycum aceh', 'Greater Victoria aryze developments', 'islandcommha', 'adam_stirling beacon community services', 'west shore', 'Aboriginal Coalition to End Homelessness', 'wsáneć anawim house', 'buckleygkml', 'alanrycroft bc housing', 'Thief', 'pacheedaht aryze developments', 'Reaching Home ', 'Tent', 'Temporary shelter', 'tsartlip bc housing', 'point ellice park', 'encampment', 'pandora avenue', 'uvic anawim house', 'kevinalbersbc aids vancouver island', 'Point in Time', 'vandupeople', 'victoria harbour cats', 'Greater Victoria Coalition to End Homelessness ', 'oak bay', 'safervic', 'tsawout aryze developments', 'councllrntaylor', 'downtown victoria business association', 'vreb aids vancouver island', 'ilfp_victoria beacon community services', 'eric_doherty', 'YYJ bc housing', \"t'sou-ke aryze developments\", 'Low-income', 'galloping goose', 'view royal', 'fernwood', 'victoriaworkbc', 'outreachsolid', 'vicplacemaking aids vancouver island', 'healthcare', 'Evicted', '1upparents bc housing', 'Victoria B.C. anawim house', 'oakbaynews', 'barclaywallace', 'rotary club of victoria', 'YYJ anawim house', 'malahat bc housing', 'malahat avi', 'sarahpottsvic beacon community services', 'salt spring island', 'emergency housing', 'nuu-chah-nulth aids vancouver island', \"t'sou-ke beacon community services\", 'colinplant2018', 'service provider', 'the cridge centre for the family', 'vfamcourt avi', 'housesooke', 'Camping', 'quadravillage', 'Poor ', 'rockheights', 'saanichnews', 'Eviction', 'the mustard seed', 'povertypimps', 'alanrycroft aryze developments', 'workingupstream', 'sarahpottsvic aids vancouver island', 'sooke homelessness coalition', 'barbdesjardins', 'burnsidegorge avi', 'ctvnewsvi', 'need_2', 'Society of St Vincent De Paul', 'kristaloughton', 'Sooke Transition House Society', 'fernwoodfca', 'salvation army victoria', 'tsartlip boys \"and\" girls club south vanouver island', 'burnsidegorge aceh', 'uvic beacon community services', 'tseycum aryze developments', 'victorianews beacon community services', 'rock bay', 'pauquachin aryze developments', 'vicyouthcouncil', 'tent', 'housing', 'mustardseedvic bc housing', 'Person experiencing homelessness ', 'Victoria Sexual Assault Centre', 'Substance use', 'photowarrior boys \"and\" girls club south vanouver island', 'songheeschief', 'greater victoria housing society', 'saanichpolice', 'brucealready avi', 'pauquachin bc housing', 'Affordable', 'nuu-chah-nulth the aboriginal coalition to end homelessness', 'pacificahousing', 'victoriadra aceh', 'sarahpottsvic aceh', 'beaconsave', 'saanich', 'our place society', 'pauquachin boys \"and\" girls club south vanouver island', \"t'sou-ke bc housing\", 'Victoria B.C. aids vancouver island', 'homeforhope', 'Greater Victoria bc housing', 'irving park', 'violence', 'rentsmartedu', 'esquimalt', 'Pacifica Housing ', 'Poverty', 'drugs', 'gracealore avi', 'the john howard society of victoria', 'Camp', 'Social structure ', 'cbcnews aryze developments', 'burnsidegorge aryze developments', 'collusion', 'sarahpottsvic the aboriginal coalition to end homelessness', 'gracealore aids vancouver island', 'nuu-chah-nulth beacon community services', 'Homeless', 'affordable', 'saanichton', 'goldstreamnews', 'peer housing support', 'front line', 'nuu-chah-nulth anawim house', 'foundry victoria', 'esquimaltnation', 'photowarrior aceh', 'cbcnews the aboriginal coalition to end homelessness', 'PovertyPimps', 'peer housing support program', 'Victoria B.C. bc housing', \"sc'ianew bc housing\", 'Makola Housing Society ', 'Affordable housing ', 'complex care', 'victoriawth anawim house', 'YYJ avi', 'The Cridge Centre for the Family ', 'drug use', 'VictoriaBC avi', 'cbcnews burnside gorge neighbourhood association', 'victoriavisitor the aboriginal coalition to end homelessness', 'restorative justice victoria', 'subsidized housing', 'BC Housing', 'murdochoakbay bc housing', 'adam_stirling aceh', 'sarahpottsvic bc housing', 'vreb', 'homeless', 'photowarrior beacon community services', 'jfatkey avi', 'oaklands park', 'hattiecosta1', 'fernwood community association', 'tseycum anawim house', 'Cool Aid', 'alanrycroft avi', 'fairfield-gonzales', 'Service provider ', 'tsawout the aboriginal coalition to end homelessness', 'cbcnews beacon community services', \"sc'ianew avi\", 'Homelessness Services Association of BC', 'vreb aceh', 'ACEH', 'chartj88', 'langford', 'quadra village community centre', 'royal athletic park', 'lived experience', 'peersvictoria', 'town of view royal', 'Overdose/overdosed ', 'gonzales', 'wsáneć aids vancouver island', \"sc'ianew aryze developments\", 'couch surfing', 'collude', 'ctess1', 'Victoria anawim house', 'VictoriaBC burnside gorge neighbourhood association', 'gracealore anawim house', 'laurel_bc', 'self_govern4us', 'pacheedaht boys \"and\" girls club south vanouver island', 'reaching home', 'nuu-chah-nulth aryze developments', 'vicplacemaking burnside gorge neighbourhood association', 'burnsidegorge burnside gorge neighbourhood association', 'uvic avi', 'sidney', 'metchosin', 'Evict', 'gracealore burnside gorge neighbourhood association', 'oaklands', 'murray_langdon', 'social housing', 'victoriavisitor burnside gorge neighbourhood association', 'timescolonist', 'the existence project', 'ninethreeseven', 'low income', 'Theft', 'Greater Victoria boys \"and\" girls club south vanouver island', 'tsartlip anawim house', '900-block pandora avenue', 't\\'sou-ke boys \"and\" girls club south vanouver island', 'tagvictoriabc avi', \"sc'ianew aids vancouver island\", 'esquimaltbc', 'mhrpsouthisland', 'pauquachin avi', 'songhees', 'ops', 'Home', 'Peer Housing Support Program', 'cbcnews bc housing', 'low-income', 'poverty', 'vreb avi', 'Victoria avi', 'vicplacemaking beacon community services', 'malahat burnside gorge neighbourhood association', 'tseycum bc housing', 'anawimhouse aids vancouver island', 'cbcnews aceh', 'island health', 'camping', \"t'sou-ke anawim house\", 'substanceuvic', 'sarahpottsvic burnside gorge neighbourhood association', 'ourplacesociety', 'sarahpottsvic anawim house', 'the backpack project', 'adriandix', 'YYJ aids vancouver island', 'vicpdcanada', 'thecridgecentre', 'harris green', 'songhees walkway', 'tsawout aids vancouver island', 'Peers Victoria Resources Society ', 'gracealore aryze developments', 'victoria chamber', 'Harm Reduction', 'vicfoundation', 'adam_stirling avi', 'Safe Supply ', 'louise_hartland burnside gorge neighbourhood association', 'sc\\'ianew boys \"and\" girls club south vanouver island', 'Temporary housing ', 'adam_stirling burnside gorge neighbourhood association', 'tsartlip avi', 'unitedatoakbay', 'kevinalbersbc boys \"and\" girls club south vanouver island', 'anawimhouse bc housing', 'YYJ the aboriginal coalition to end homelessness', 'beacon hill park', 'louise_hartland avi', 'safer victoria', 'Victoria bc housing', 'Victoria aceh', 'murdochoakbay burnside gorge neighbourhood association', 'viccoolaid', 'point in time', 'mustardseedvic anawim house', 'affordable housing', 'YYJ aryze developments', 'Anawim', 'Salvation Army', 'malahat aceh', 'davidhscreech', 'rockland', 'victorianews burnside gorge neighbourhood association', 'photowarrior anawim house', 'talktoaryze', 'kevinalbersbc avi', 'kwakwaka’wakw', 'burnsidegorge aids vancouver island', 'Society of St Vincent De Paul Van Island', 'stadacona park', 'burnsidegorge beacon community services', 'lekwungen', 'substance uvic', 'theft', 'murdochoakbay anawim house', 'PiT', 'chiefmanak', 'tagvictoriabc aids vancouver island', 'vic west', 'sarahpottsvic aryze developments', 'mhsvictoria avi', 'mustardseedvic burnside gorge neighbourhood association', 'coryresilient', 'mydvba', 'youngparentssup', 'tsawout burnside gorge neighbourhood association', 'pauquachin aceh', 'safervic bc housing', 'stolen', 'vancouver island mental health society', 'Victoria aids vancouver island', 'adam_stirling aids vancouver island', 'SVDP', 'marikaalbert', 'quadra', 'Camper', 'frontline worker ', 'VictoriaBC the aboriginal coalition to end homelessness', 'central park', 'Victoria burnside gorge neighbourhood association', 'coreyranger', 'jeremyloveday', \"sc'ianew the aboriginal coalition to end homelessness\", 'tsartlip burnside gorge neighbourhood association', 'Victoria B.C. avi', 'evicted', 'tsawout boys \"and\" girls club south vanouver island', 'workbc', 'spaynebc', 'selkirk green', 'coast salish', 'avivanisle', 'evict', 'literacy victoria', 'tsartlip aids vancouver island', 'pauquachin aids vancouver island', 'pacheedaht anawim house', 'carolinaibarra', 'Peer Housing Support', 'gracealore the aboriginal coalition to end homelessness', 'victoria west', 'nuu-chah-nulth burnside gorge neighbourhood association', 'foul bay', 'victorianews aids vancouver island', 'pit', 'sarahpottsvic avi', 'soap4hopeyyj', 'nuu-chah-nulth avi', 'topaz park', 'vicplacemaking the aboriginal coalition to end homelessness', 'rentsmart', 'murdochoakbay aceh', 'wsáneć the aboriginal coalition to end homelessness', 'the victoria real estate board', 'alcoholic', 'VictoriaBC boys \"and\" girls club south vanouver island', 'vicplacemaking avi', 'r_garrison', 'darylbassett3', 'murdochoakbay the aboriginal coalition to end homelessness', 'berniepauly', 'thief', 'Shelter', 'vibrant victoria', 'safervic aceh', 'Victoria B.C. aryze developments', 'bc_housing', 'sookecoalition', 'the downtown victoria business association', 'the victoria foundation', 'majatait', \"t'sou-ke burnside gorge neighbourhood association\", 'millstream', 'victoriadra the aboriginal coalition to end homelessness', 'malahat beacon community services', 'nuu-chah-nulth bc housing', 'victoria brain injury society', 'shelter', 'district of north saanich', 'YYJ burnside gorge neighbourhood association', 'hilarylmarks', 'cspc_victoria avi', 'zacdevries avi', 'adam_stirling bc housing', 'tagvictoriabc aceh', 'zacdevries burnside gorge neighbourhood association', 'colwood', 'camp', 'Social Housing ', 'temporary shelter', 'foundryvictoria', 'houseanawim', 'vicplacemaking bc housing', 'victoriavisitor aids vancouver island', 'yyj_housing', 'pit count', 'tagvictoriabc boys \"and\" girls club south vanouver island', 'Healthcare ', 'Encampments', 'VictoriaBC bc housing', \"sc'ianew beacon community services\", 'Alcoholic ', 'victoriavisitor aceh', 'adampolsen', 'dvba', 'gracealore aceh', 'tsartlip aryze developments', 'vicplacemaking aryze developments', 'VWTH', \"t'sou-ke aceh\", 'Affordable Housing', 'tenant action group victoria', 'photowarrior the aboriginal coalition to end homelessness', 'wsáneć aceh', 'united way southern vancouver island', 'kevinalbersbc bc housing', \"sc'ianew burnside gorge neighbourhood association\", 'victoria ready', 'poor', 'Unhoused ', 'pacheedaht aids vancouver island', 'Victoria B.C. boys \"and\" girls club south vanouver island', 'vic west park', 'Tiny Town', 'Encampment', 'louise_hartland aryze developments', 'tsartlip aceh', 'pacheedaht beacon community services', 'tsawout anawim house', 'kevinalbersbc aceh', 'wschamber1', 'tseycum beacon community services', 'VictoriaBC aceh', 'narcotics', 'Our Place', 'Crime ', 'charlesbodi', 'pacheedaht bc housing', 'WiN', 'malahat anawim house', 'sookenews', '#PovertyPimps', 'Emergency Housing ', 'vreb anawim house', 'Coordinated Access and Assessment ', 'Couch-surfing', 'eviction', 'uplands', 'tourismvi', 'township of esquimalt', '#YYJ boys \"and\" girls club south vanouver island', 'anawimhouse boys \"and\" girls club south vanouver island', 'juan de fuca', 'Victoria boys \"and\" girls club south vanouver island', 'addict', 'victoria', 'SOLID Outreach ', 'VictoriaBC aids vancouver island', 'cspoliceservice', 'vanislandhealth', 'victoria native friendship centre', 'coordinated access \"and\" assessment', 'tsartlip beacon community services', 'chek_news', 'Greater Victoria aids vancouver island', 'yyjpolitics', 'YYJ aceh', 'Social problem ', 'sarahpottsvic boys \"and\" girls club south vanouver island', 'addicted', 'the homeless ideas podcast', 'wearenorthpark', 'solid outreach', 'victoriadra bc housing', 'Low income', 'victorianews anawim house', 'katstinson', 'cbcnews avi', 'fairfield_comm', 'louise_hartland anawim house', 'vreb bc housing', 'elizabethmay', 'victoria family court', 'homelessness', \"t'sou-ke avi\", 'vfamcourt burnside gorge neighbourhood association', 'wsáneć boys \"and\" girls club south vanouver island', 'pacheedaht burnside gorge neighbourhood association', 'frontline worker', 'Victoria Native Friendship Centre ', 'vicplacemaking anawim house', 'pacheedaht aceh', 'cbcnews boys \"and\" girls club south vanouver island', 'pacheedaht the aboriginal coalition to end homelessness', 'shelliegudgeon', 'nuu-chah-nulth boys \"and\" girls club south vanouver island', 'uvic aids vancouver island', 'victorianews boys \"and\" girls club south vanouver island', 'vicplacemaking aceh', 'victorianews aryze developments', 'tseycum avi', 'pacifica housing', 'makolahousing', 'saltspringx', 'Victoria aryze developments', 'YYJ boys \"and\" girls club south vanouver island', 'jfatkey bc housing', 'alanrycroft boys \"and\" girls club south vanouver island', 'johnhoward_can', 'pauquachin anawim house', 'victorianews avi', 'cityofvictoria', 'vreb boys \"and\" girls club south vanouver island', 'varcsvictoria', 'red cedar café', 'murdochoakbay avi', 'nicolechaland', 'overdose', 'Foundry Victoria ', 'victoria sexual assault centre', 'thebackpackpro1', 'tagvictoriabc burnside gorge neighbourhood association', 'wsáneć burnside gorge neighbourhood association', 'homelessness services association of bc', \"sc'ianew aceh\", 'mustardseedvic avi', 'murdochoakbay boys \"and\" girls club south vanouver island', 'photowarrior avi', 'adam_stirling boys \"and\" girls club south vanouver island', 'Violence', 'selkirk trestle', 'umbrella society', \"sc'ianew anawim house\", 'firstmetvic', 'Addict', 'Homelessness ', 'Greater Victoria Coalition to End Homelessness bc housing', 'alanrycroft burnside gorge neighbourhood association', 'greater victoria coalition to end homelessness', 'malahat aryze developments', 'malahat boys \"and\" girls club south vanouver island', 'mhsvictoria boys \"and\" girls club south vanouver island', 'Subsidized Housing ', 'louise_hartland aceh', 'tsawout aceh', 'Umbrella Society ', 'malahat aids vancouver island', 'jamesbaycp', 'Community Plan to End Homelessness ', 'Victoria Women in Need', 'togethervic', 'Greater Victoria aceh', 'beaconhillfolks', 'existenceprojct', 'city of colwood', 'victoria placemaking', 'city of langford', 'pacochran', 'Victoria the aboriginal coalition to end homelessness', 'tagvictoriabc the aboriginal coalition to end homelessness', 'mhsvictoria anawim house', 'pauquachin burnside gorge neighbourhood association', 'tseycum boys \"and\" girls club south vanouver island', 'sjavicbc', 'stephen_andrew', 'unhoused', 'vfamcourt aceh', 'victorianews bc housing', 'nuu-chah-nulth', 'cfax1070', 'camper', 'cspc_victoria boys \"and\" girls club south vanouver island', '1upparents boys \"and\" girls club south vanouver island', 'frontline', 'Frontline', 'umbrellasociety', 'extremeoutreach', 'victoriabuzzes', 'adam_stirling anawim house', 'salarmyvicarc', 'wsáneć aryze developments', '1upparents avi', 'community plan to end homelessness', 'Narcotics ', 'greater victoria acting together', 'dave_eby', 'front line worker', 'victorianews the aboriginal coalition to end homelessness', 'Drugs', 'cook street village', 'gracealore boys \"and\" girls club south vanouver island', 'malahat the aboriginal coalition to end homelessness', 'acehsociety', 'habitat for humanity victoria', 'gracealore bc housing', 'victoria women in need', 'harm reduction', 'overdosed', 'safe supply', 'Addicted', 'tsawout avi', 'Collude', 'tagvictoriabc beacon community services', 'svdpvi', 'city of victoria', 'uvic aryze developments', 'people with lived experience', 'the gorge', 'PiT Count', 'photowarrior aids vancouver island', 'alanrycroft anawim house', 'victoriasandy', 'Greater Victoria avi', 'habitatvictoria', 'victoria tenant action group', 'crd_bc', 'vreb beacon community services', 'cecelia ravine park', 'Complex care ', 'district of saanich', 'social structure', 'Stolen', 'wsáneć beacon community services', 'crime', 'gonzales park', 'tseycum burnside gorge neighbourhood association']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import asyncpraw.models\n",
        "\n",
        "# async def fetch_data(reddit, subreddit_names, search_terms, limit_num=5000):\n",
        "#     titles = []\n",
        "#     texts = []\n",
        "#     user_ids = []\n",
        "#     comments = []\n",
        "#     subreddits = []\n",
        "#     used_search_terms = []\n",
        "\n",
        "#     # Ensure that subreddit_names is a list\n",
        "#     if not isinstance(subreddit_names, list):\n",
        "#         print(\"Error: subreddit_names should be a list.\")\n",
        "#         return pd.DataFrame()  # Return an empty DataFrame\n",
        "\n",
        "#     # Ensure that search_terms is a list\n",
        "#     if not isinstance(search_terms, list):\n",
        "#         print(\"Error: search_terms should be a list.\")\n",
        "#         return pd.DataFrame()  # Return an empty DataFrame\n",
        "\n",
        "#     for subreddit_name in subreddit_names:\n",
        "#         print(f\"\\nFetching data from subreddit: {subreddit_name}\")\n",
        "#         subreddit = await reddit.subreddit(subreddit_name)\n",
        "#         for search_term in search_terms:\n",
        "#             # Ensure each search_term is a string\n",
        "#             if not isinstance(search_term, str):\n",
        "#                 print(f\"Error: search_term '{search_term}' is not a string.\")\n",
        "#                 continue  # Skip this search term\n",
        "\n",
        "#             print(f\"Searching for term: {search_term}\")\n",
        "#             submissions = []\n",
        "#             async for submission in subreddit.search(search_term, limit=limit_num):\n",
        "#                 submissions.append(submission)\n",
        "#             print(f\"Found {len(submissions)} submissions for term '{search_term}' in subreddit '{subreddit_name}'\")\n",
        "\n",
        "#             for submission in submissions:\n",
        "#                 print(f\"Processing submission: {submission.id}\")\n",
        "#                 await asyncio.sleep(1)\n",
        "#                 await submission.load()\n",
        "#                 comment_queue = submission.comments[:]\n",
        "\n",
        "#                 comment_count = 0\n",
        "#                 while comment_queue:\n",
        "#                     comment = comment_queue.pop(0)\n",
        "#                     if isinstance(comment, asyncpraw.models.Comment):\n",
        "#                         titles.append(submission.title)\n",
        "#                         texts.append(submission.selftext)\n",
        "#                         user_ids.append(submission.author.name if submission.author else None)\n",
        "#                         comments.append(comment.body)\n",
        "#                         subreddits.append(subreddit_name)\n",
        "#                         used_search_terms.append(search_term)\n",
        "#                         comment_count += 1\n",
        "#                     elif isinstance(comment, asyncpraw.models.MoreComments):\n",
        "#                         more_comments = await comment.comments()\n",
        "#                         comment_queue.extend(more_comments)\n",
        "\n",
        "#                 print(f\"Appended {comment_count} comments for submission {submission.id}\")\n",
        "\n",
        "#     df = pd.DataFrame({\n",
        "#         'Subreddit': subreddits,\n",
        "#         'Title': titles,\n",
        "#         'Text': texts,\n",
        "#         'User ID': user_ids,\n",
        "#         'Comment': comments,\n",
        "#         'Search Term': used_search_terms\n",
        "#     })\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "LCJvscRL070m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from asyncprawcore.exceptions import RequestException, ResponseException\n",
        "\n",
        "# async def fetch_subreddit_data(reddit, subreddit_name, search_term, limit_num=5000):\n",
        "#     titles = []\n",
        "#     texts = []\n",
        "#     user_ids = []\n",
        "#     comments = []\n",
        "#     subreddits = []\n",
        "\n",
        "#     print(f\"Fetching data from subreddit: {subreddit_name} for term: {search_term}\")\n",
        "#     subreddit = await reddit.subreddit(subreddit_name)\n",
        "#     submissions = []  # Initialize submissions here\n",
        "\n",
        "#     try:\n",
        "#         submissions = [submission async for submission in subreddit.search(search_term, limit=limit_num)]\n",
        "#     except ResponseException as e:\n",
        "#         print(f\"Rate limit exceeded when fetching submissions: {e}\")\n",
        "#         # Optionally, you can handle this with a retry mechanism\n",
        "\n",
        "#     print(f\"Found {len(submissions)} submissions for term '{search_term}' in subreddit '{subreddit_name}'\")\n",
        "\n",
        "#     for submission in submissions:\n",
        "#         print(f\"Processing submission {submission.id}\")\n",
        "#         retry_delay = 10  # Start with a 10-second delay\n",
        "#         max_retries = 5   # Maximum number of retries\n",
        "#         current_retry = 0\n",
        "\n",
        "#         while current_retry < max_retries:\n",
        "#             try:\n",
        "#                 await asyncio.sleep(retry_delay)  # Sleep to respect rate limits\n",
        "#                 titles.append(submission.title)\n",
        "#                 texts.append(submission.selftext)\n",
        "#                 user_ids.append(submission.author.name if submission.author else None)\n",
        "#                 subreddits.append(subreddit_name)\n",
        "\n",
        "#                 # Fetch comments for the submission\n",
        "#                 submission.comment_sort = 'new'\n",
        "#                 comments_list = await submission.comments()\n",
        "#                 await comments_list.replace_more(limit=0)\n",
        "#                 for comment in comments_list.list():\n",
        "#                     comments.append(comment.body)\n",
        "#                 break  # Break the loop if successful\n",
        "#             except RequestException as e:\n",
        "#                 print(f\"Rate limit exceeded when fetching comments: {e}. Retrying in {retry_delay} seconds.\")\n",
        "#                 retry_delay *= 2  # Double the delay\n",
        "#                 current_retry += 1\n",
        "\n",
        "#         if current_retry == max_retries:\n",
        "#             print(f\"Maximum retries reached for submission {submission.id}. Moving to next.\")\n",
        "\n",
        "#     return titles, texts, user_ids, comments, subreddits\n",
        "\n",
        "# # This function will handle the concurrency and combine the results into a single DataFrame.\n",
        "# async def fetch_data(reddit, subreddit_names, search_terms, limit_num=5000):\n",
        "#     tasks = []\n",
        "#     for subreddit_name in subreddit_names:\n",
        "#         for search_term in search_terms:\n",
        "#             task = fetch_subreddit_data(reddit, subreddit_name, search_term, limit_num)\n",
        "#             tasks.append(task)\n",
        "\n",
        "#     results = await asyncio.gather(*tasks)\n",
        "\n",
        "#     # Flatten the results and create a DataFrame\n",
        "#     all_titles, all_texts, all_user_ids, all_comments, all_subreddits = [], [], [], [], []\n",
        "#     for result in results:\n",
        "#         titles, texts, user_ids, comments, subreddits = result\n",
        "#         all_titles.extend(titles)\n",
        "#         all_texts.extend(texts)\n",
        "#         all_user_ids.extend(user_ids)\n",
        "#         all_comments.extend(comments)\n",
        "#         all_subreddits.extend(subreddits)\n",
        "\n",
        "#     df = pd.DataFrame({\n",
        "#         'Subreddit': all_subreddits,\n",
        "#         'Title': all_titles,\n",
        "#         'Text': all_texts,\n",
        "#         'User ID': all_user_ids,\n",
        "#         'Comment': all_comments\n",
        "#     })\n",
        "\n",
        "#     return df"
      ],
      "metadata": {
        "id": "8RuVmYC6A74e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncpraw.models\n",
        "\n",
        "async def fetch_data(reddit, subreddit_names, search_terms, limit_num=10000):\n",
        "    titles = []\n",
        "    texts = []\n",
        "    submission_ids = []\n",
        "    user_ids = []\n",
        "    comments = []\n",
        "    subreddits = []\n",
        "    used_search_terms = []\n",
        "\n",
        "    # Ensure that subreddit_names is a list\n",
        "    if not isinstance(subreddit_names, list):\n",
        "        print(\"Error: subreddit_names should be a list.\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame\n",
        "\n",
        "    # Ensure that search_terms is a list\n",
        "    if not isinstance(search_terms, list):\n",
        "        print(\"Error: search_terms should be a list.\")\n",
        "        return pd.DataFrame()  # Return an empty DataFrame\n",
        "\n",
        "    for subreddit_name in subreddit_names:\n",
        "        print(f\"\\nFetching data from subreddit: {subreddit_name}\")\n",
        "        subreddit = await reddit.subreddit(subreddit_name)\n",
        "        for search_term in search_terms:\n",
        "            # Ensure each search_term is a string\n",
        "            if not isinstance(search_term, str):\n",
        "                print(f\"Error: search_term '{search_term}' is not a string.\")\n",
        "                continue  # Skip this search term\n",
        "\n",
        "            print(f\"Searching for term: {search_term}\")\n",
        "            submissions = []\n",
        "            async for submission in subreddit.search(search_term, limit=limit_num):\n",
        "                submissions.append(submission)\n",
        "            print(f\"Found {len(submissions)} submissions for term '{search_term}' in subreddit '{subreddit_name}'\")\n",
        "\n",
        "            for submission in submissions:\n",
        "                print(f\"Processing submission: {submission.id}\")\n",
        "                await asyncio.sleep(1)\n",
        "                await submission.load()\n",
        "\n",
        "                titles.append(submission.title)\n",
        "                texts.append(submission.selftext)\n",
        "                submission_ids.append(submission.id)\n",
        "                user_ids.append(submission.author.name if submission.author else None)\n",
        "                subreddits.append(subreddit_name)\n",
        "                used_search_terms.append(search_term)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'Subreddit': subreddits,\n",
        "        'Title': titles,\n",
        "        'Text': texts,\n",
        "        'Submission ID': submission_ids,\n",
        "        'User ID': user_ids,\n",
        "        'Comment': comments,\n",
        "        'Search Term': used_search_terms\n",
        "    })\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "05uAEuxDI7PR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    df = await fetch_data(reddit, subreddits_list, search_terms)\n",
        "\n",
        "    await reddit.close()\n",
        "    return df\n",
        "\n",
        "# Run the main function and get the DataFrame\n",
        "reddit_data_search_terms = await main()\n",
        "# Save the DataFrame to a CSV file\n",
        "# Path to the CSV file\n",
        "file_path = '/content/SWB-GVCEH/data/reddit_data_search_terms.csv'\n",
        "\n",
        "reddit_data_search_terms = reddit_data_search_terms.drop_duplicates().reset_index(drop=True)\n",
        "reddit_data_search_terms.to_csv(file_path, index=False)\n",
        "print(\"Data fetched and saved to reddit_data_search_terms.csv\")\n",
        "\n",
        "# Trigger a download to your local machine\n",
        "files.download(file_path)\n",
        "\n",
        "# # Set your git remote URL to include the PAT for authentication\n",
        "# repo_url = 'https://github.com/alex-jk/SWB-GVCEH.git'  # Replace with your repository's URL\n",
        "# pat = os.environ['GITHUB_PAT']\n",
        "# repo_url_with_token = repo_url[:8] + pat + \"@\" + repo_url[8:]\n",
        "\n",
        "# !git remote set-url origin {repo_url_with_token}\n",
        "\n",
        "# # Navigate to the repository directory, add, commit, and push the new CSV file\n",
        "# %cd /content/SWB-GVCEH\n",
        "# !git add 'data/reddit_data_search_terms.csv'\n",
        "# !git commit -m \"Add fetched Reddit data search terms CSV\"\n",
        "# !git push origin main  # Replace 'main' with your branch name if it's different\n",
        "\n",
        "# # Reset the remote URL to the original without the PAT\n",
        "# !git remote set-url origin {repo_url}\n",
        "# print(\"CSV file pushed to GitHub.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "79qRrHRP1CX8",
        "outputId": "68205b8e-84ee-4cfe-b8c4-59c9b8eab4ff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fetching data from subreddit: Sooke\n",
            "Searching for term: north park\n",
            "Found 0 submissions for term 'north park' in subreddit 'Sooke'\n",
            "Searching for term: louise_hartland bc housing\n",
            "Found 0 submissions for term 'louise_hartland bc housing' in subreddit 'Sooke'\n",
            "Searching for term: cool aid society\n",
            "Found 0 submissions for term 'cool aid society' in subreddit 'Sooke'\n",
            "Searching for term: drcvictoria\n",
            "Found 0 submissions for term 'drcvictoria' in subreddit 'Sooke'\n",
            "Searching for term: social problem\n",
            "Found 0 submissions for term 'social problem' in subreddit 'Sooke'\n",
            "Searching for term: spd_community\n",
            "Found 0 submissions for term 'spd_community' in subreddit 'Sooke'\n",
            "Searching for term: substance use\n",
            "Found 0 submissions for term 'substance use' in subreddit 'Sooke'\n",
            "Searching for term: photowarrior bc housing\n",
            "Found 0 submissions for term 'photowarrior bc housing' in subreddit 'Sooke'\n",
            "Searching for term: adam_stirling aryze developments\n",
            "Found 0 submissions for term 'adam_stirling aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: burnside-gorge\n",
            "Found 0 submissions for term 'burnside-gorge' in subreddit 'Sooke'\n",
            "Searching for term: mental health society of greater victoria\n",
            "Found 2 submissions for term 'mental health society of greater victoria' in subreddit 'Sooke'\n",
            "Processing submission: 7t1tr6\n",
            "Processing submission: jkmif2\n",
            "Searching for term: victorianews aceh\n",
            "Found 0 submissions for term 'victorianews aceh' in subreddit 'Sooke'\n",
            "Searching for term: cbcnews anawim house\n",
            "Found 0 submissions for term 'cbcnews anawim house' in subreddit 'Sooke'\n",
            "Searching for term: nuu-chah-nulth aceh\n",
            "Found 0 submissions for term 'nuu-chah-nulth aceh' in subreddit 'Sooke'\n",
            "Searching for term: Greater Victoria beacon community services\n",
            "Found 1 submissions for term 'Greater Victoria beacon community services' in subreddit 'Sooke'\n",
            "Processing submission: 7w5qhj\n",
            "Searching for term: quadra village\n",
            "Found 0 submissions for term 'quadra village' in subreddit 'Sooke'\n",
            "Searching for term: pacheedaht avi\n",
            "Found 0 submissions for term 'pacheedaht avi' in subreddit 'Sooke'\n",
            "Searching for term: YYJ beacon community services\n",
            "Found 0 submissions for term 'YYJ beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: pauquachin beacon community services\n",
            "Found 0 submissions for term 'pauquachin beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: 1upparents anawim house\n",
            "Found 0 submissions for term '1upparents anawim house' in subreddit 'Sooke'\n",
            "Searching for term: makola housing society\n",
            "Found 1 submissions for term 'makola housing society' in subreddit 'Sooke'\n",
            "Processing submission: t98a89\n",
            "Searching for term: lochside\n",
            "Found 0 submissions for term 'lochside' in subreddit 'Sooke'\n",
            "Searching for term: tseycum aids vancouver island\n",
            "Found 3 submissions for term 'tseycum aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: wsáneć bc housing\n",
            "Found 0 submissions for term 'wsáneć bc housing' in subreddit 'Sooke'\n",
            "Searching for term: hollywood park\n",
            "Found 0 submissions for term 'hollywood park' in subreddit 'Sooke'\n",
            "Searching for term: gracealore beacon community services\n",
            "Found 0 submissions for term 'gracealore beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: murdochoakbay aryze developments\n",
            "Found 0 submissions for term 'murdochoakbay aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: sooke\n",
            "Found 104 submissions for term 'sooke' in subreddit 'Sooke'\n",
            "Processing submission: dww9sf\n",
            "Processing submission: 8yet0v\n",
            "Processing submission: rprnmu\n",
            "Processing submission: tnw6b8\n",
            "Processing submission: qweq6o\n",
            "Processing submission: quj929\n",
            "Processing submission: mqfx4z\n",
            "Processing submission: ok8cjn\n",
            "Processing submission: pyz5ox\n",
            "Processing submission: m59ist\n",
            "Processing submission: t98a89\n",
            "Processing submission: tlwv08\n",
            "Processing submission: raroao\n",
            "Processing submission: p7wprf\n",
            "Processing submission: m84wlr\n",
            "Processing submission: m88g9g\n",
            "Processing submission: hkdzor\n",
            "Processing submission: p00u2m\n",
            "Processing submission: nr13l7\n",
            "Processing submission: lcvt6x\n",
            "Processing submission: lzgvjq\n",
            "Processing submission: mw6cun\n",
            "Processing submission: qvip51\n",
            "Processing submission: 85hp7d\n",
            "Processing submission: mnm303\n",
            "Processing submission: 95i5ys\n",
            "Processing submission: pyb06g\n",
            "Processing submission: bjdqku\n",
            "Processing submission: l6oyw1\n",
            "Processing submission: 7w5qhj\n",
            "Processing submission: qvipcm\n",
            "Processing submission: e2yd54\n",
            "Processing submission: 7x1nnf\n",
            "Processing submission: 7phfrd\n",
            "Processing submission: 3kcf1n\n",
            "Processing submission: 7of4w2\n",
            "Processing submission: juv4s4\n",
            "Processing submission: 71lbrd\n",
            "Processing submission: 7vsy01\n",
            "Processing submission: 5lc7sy\n",
            "Processing submission: 8dgh63\n",
            "Processing submission: lms4ms\n",
            "Processing submission: 70c9eh\n",
            "Processing submission: aj09or\n",
            "Processing submission: 6tu58g\n",
            "Processing submission: 7665km\n",
            "Processing submission: 680z2s\n",
            "Processing submission: yjk0h\n",
            "Processing submission: 7ovak1\n",
            "Processing submission: 7t1tr6\n",
            "Processing submission: 78j8ea\n",
            "Processing submission: 7k45c3\n",
            "Processing submission: cnw2b1\n",
            "Processing submission: 6wxa2o\n",
            "Processing submission: qy51yv\n",
            "Processing submission: 8ad0zy\n",
            "Processing submission: 2pjjqa\n",
            "Processing submission: 86pm21\n",
            "Processing submission: 853s9f\n",
            "Processing submission: c2j02s\n",
            "Processing submission: d88fk6\n",
            "Processing submission: 898kja\n",
            "Processing submission: 7afauv\n",
            "Processing submission: 7w702d\n",
            "Processing submission: 7of3zp\n",
            "Processing submission: qwj4e3\n",
            "Processing submission: 7qtest\n",
            "Processing submission: lg1ygu\n",
            "Processing submission: 8eo4kw\n",
            "Processing submission: hfgav6\n",
            "Processing submission: 4tw0oo\n",
            "Processing submission: 4ti4yn\n",
            "Processing submission: ghjs1l\n",
            "Processing submission: ckd364\n",
            "Processing submission: 5lcb56\n",
            "Processing submission: 3vj23x\n",
            "Processing submission: 2cajpi\n",
            "Processing submission: 44ukwu\n",
            "Processing submission: qz951u\n",
            "Processing submission: t61vrr\n",
            "Processing submission: qqkdkl\n",
            "Processing submission: sogzni\n",
            "Processing submission: q6yp66\n",
            "Processing submission: pi5iei\n",
            "Processing submission: pl37lw\n",
            "Processing submission: ivytg2\n",
            "Processing submission: o5wqxu\n",
            "Processing submission: ldqga2\n",
            "Processing submission: i70xhp\n",
            "Processing submission: kbrq2f\n",
            "Processing submission: cf9r1v\n",
            "Processing submission: jkmif2\n",
            "Processing submission: i8755x\n",
            "Processing submission: hlhw67\n",
            "Processing submission: bryslb\n",
            "Processing submission: dpd33d\n",
            "Processing submission: crmwld\n",
            "Processing submission: 7lpchz\n",
            "Processing submission: 7i3nv0\n",
            "Processing submission: 6doy7i\n",
            "Processing submission: 6uek0z\n",
            "Processing submission: 5eueqx\n",
            "Processing submission: 5sv6rw\n",
            "Processing submission: 16gbcx\n",
            "Searching for term: VictoriaBC anawim house\n",
            "Found 0 submissions for term 'VictoriaBC anawim house' in subreddit 'Sooke'\n",
            "Searching for term: tagvictoriabc bc housing\n",
            "Found 0 submissions for term 'tagvictoriabc bc housing' in subreddit 'Sooke'\n",
            "Searching for term: Victoria beacon community services\n",
            "Found 0 submissions for term 'Victoria beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: Lived Experience\n",
            "Found 0 submissions for term 'Lived Experience' in subreddit 'Sooke'\n",
            "Searching for term: tsawout beacon community services\n",
            "Found 0 submissions for term 'tsawout beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: t'sou-ke aids vancouver island\n",
            "Found 3 submissions for term 't'sou-ke aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: Victoria Women's Transition House\n",
            "Found 0 submissions for term 'Victoria Women's Transition House' in subreddit 'Sooke'\n",
            "Searching for term: south_island_c\n",
            "Found 0 submissions for term 'south_island_c' in subreddit 'Sooke'\n",
            "Searching for term: Sooke Homelessness Coalition\n",
            "Found 0 submissions for term 'Sooke Homelessness Coalition' in subreddit 'Sooke'\n",
            "Searching for term: wsáneć avi\n",
            "Found 0 submissions for term 'wsáneć avi' in subreddit 'Sooke'\n",
            "Searching for term: peers victoria resources society\n",
            "Found 0 submissions for term 'peers victoria resources society' in subreddit 'Sooke'\n",
            "Searching for term: cspc_victoria bc housing\n",
            "Found 0 submissions for term 'cspc_victoria bc housing' in subreddit 'Sooke'\n",
            "Searching for term: tsawout bc housing\n",
            "Found 0 submissions for term 'tsawout bc housing' in subreddit 'Sooke'\n",
            "Searching for term: hillside-quadra\n",
            "Found 0 submissions for term 'hillside-quadra' in subreddit 'Sooke'\n",
            "Searching for term: People with lived experience\n",
            "Found 0 submissions for term 'People with lived experience' in subreddit 'Sooke'\n",
            "Searching for term: Housing\n",
            "Found 5 submissions for term 'Housing' in subreddit 'Sooke'\n",
            "Processing submission: 71lbrd\n",
            "Processing submission: lms4ms\n",
            "Processing submission: mw6cun\n",
            "Processing submission: t98a89\n",
            "Processing submission: 44ukwu\n",
            "Searching for term: victoria real estate board\n",
            "Found 2 submissions for term 'victoria real estate board' in subreddit 'Sooke'\n",
            "Processing submission: rprnmu\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: person experiencing homelessness\n",
            "Found 0 submissions for term 'person experiencing homelessness' in subreddit 'Sooke'\n",
            "Searching for term: tseycum aceh\n",
            "Found 0 submissions for term 'tseycum aceh' in subreddit 'Sooke'\n",
            "Searching for term: Greater Victoria aryze developments\n",
            "Found 1 submissions for term 'Greater Victoria aryze developments' in subreddit 'Sooke'\n",
            "Processing submission: 7w5qhj\n",
            "Searching for term: islandcommha\n",
            "Found 0 submissions for term 'islandcommha' in subreddit 'Sooke'\n",
            "Searching for term: adam_stirling beacon community services\n",
            "Found 0 submissions for term 'adam_stirling beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: west shore\n",
            "Found 0 submissions for term 'west shore' in subreddit 'Sooke'\n",
            "Searching for term: Aboriginal Coalition to End Homelessness\n",
            "Found 0 submissions for term 'Aboriginal Coalition to End Homelessness' in subreddit 'Sooke'\n",
            "Searching for term: wsáneć anawim house\n",
            "Found 0 submissions for term 'wsáneć anawim house' in subreddit 'Sooke'\n",
            "Searching for term: buckleygkml\n",
            "Found 0 submissions for term 'buckleygkml' in subreddit 'Sooke'\n",
            "Searching for term: alanrycroft bc housing\n",
            "Found 0 submissions for term 'alanrycroft bc housing' in subreddit 'Sooke'\n",
            "Searching for term: Thief\n",
            "Found 0 submissions for term 'Thief' in subreddit 'Sooke'\n",
            "Searching for term: pacheedaht aryze developments\n",
            "Found 0 submissions for term 'pacheedaht aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: Reaching Home \n",
            "Found 0 submissions for term 'Reaching Home ' in subreddit 'Sooke'\n",
            "Searching for term: Tent\n",
            "Found 1 submissions for term 'Tent' in subreddit 'Sooke'\n",
            "Processing submission: m59ist\n",
            "Searching for term: Temporary shelter\n",
            "Found 0 submissions for term 'Temporary shelter' in subreddit 'Sooke'\n",
            "Searching for term: tsartlip bc housing\n",
            "Found 0 submissions for term 'tsartlip bc housing' in subreddit 'Sooke'\n",
            "Searching for term: point ellice park\n",
            "Found 0 submissions for term 'point ellice park' in subreddit 'Sooke'\n",
            "Searching for term: encampment\n",
            "Found 0 submissions for term 'encampment' in subreddit 'Sooke'\n",
            "Searching for term: pandora avenue\n",
            "Found 0 submissions for term 'pandora avenue' in subreddit 'Sooke'\n",
            "Searching for term: uvic anawim house\n",
            "Found 0 submissions for term 'uvic anawim house' in subreddit 'Sooke'\n",
            "Searching for term: kevinalbersbc aids vancouver island\n",
            "Found 3 submissions for term 'kevinalbersbc aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: Point in Time\n",
            "Found 0 submissions for term 'Point in Time' in subreddit 'Sooke'\n",
            "Searching for term: vandupeople\n",
            "Found 0 submissions for term 'vandupeople' in subreddit 'Sooke'\n",
            "Searching for term: victoria harbour cats\n",
            "Found 0 submissions for term 'victoria harbour cats' in subreddit 'Sooke'\n",
            "Searching for term: Greater Victoria Coalition to End Homelessness \n",
            "Found 0 submissions for term 'Greater Victoria Coalition to End Homelessness ' in subreddit 'Sooke'\n",
            "Searching for term: oak bay\n",
            "Found 1 submissions for term 'oak bay' in subreddit 'Sooke'\n",
            "Processing submission: 6uek0z\n",
            "Searching for term: safervic\n",
            "Found 0 submissions for term 'safervic' in subreddit 'Sooke'\n",
            "Searching for term: tsawout aryze developments\n",
            "Found 0 submissions for term 'tsawout aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: councllrntaylor\n",
            "Found 0 submissions for term 'councllrntaylor' in subreddit 'Sooke'\n",
            "Searching for term: downtown victoria business association\n",
            "Found 0 submissions for term 'downtown victoria business association' in subreddit 'Sooke'\n",
            "Searching for term: vreb aids vancouver island\n",
            "Found 3 submissions for term 'vreb aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: ilfp_victoria beacon community services\n",
            "Found 0 submissions for term 'ilfp_victoria beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: eric_doherty\n",
            "Found 0 submissions for term 'eric_doherty' in subreddit 'Sooke'\n",
            "Searching for term: YYJ bc housing\n",
            "Found 0 submissions for term 'YYJ bc housing' in subreddit 'Sooke'\n",
            "Searching for term: t'sou-ke aryze developments\n",
            "Found 0 submissions for term 't'sou-ke aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: Low-income\n",
            "Found 0 submissions for term 'Low-income' in subreddit 'Sooke'\n",
            "Searching for term: galloping goose\n",
            "Found 0 submissions for term 'galloping goose' in subreddit 'Sooke'\n",
            "Searching for term: view royal\n",
            "Found 0 submissions for term 'view royal' in subreddit 'Sooke'\n",
            "Searching for term: fernwood\n",
            "Found 0 submissions for term 'fernwood' in subreddit 'Sooke'\n",
            "Searching for term: victoriaworkbc\n",
            "Found 0 submissions for term 'victoriaworkbc' in subreddit 'Sooke'\n",
            "Searching for term: outreachsolid\n",
            "Found 0 submissions for term 'outreachsolid' in subreddit 'Sooke'\n",
            "Searching for term: vicplacemaking aids vancouver island\n",
            "Found 3 submissions for term 'vicplacemaking aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: healthcare\n",
            "Found 0 submissions for term 'healthcare' in subreddit 'Sooke'\n",
            "Searching for term: Evicted\n",
            "Found 0 submissions for term 'Evicted' in subreddit 'Sooke'\n",
            "Searching for term: 1upparents bc housing\n",
            "Found 0 submissions for term '1upparents bc housing' in subreddit 'Sooke'\n",
            "Searching for term: Victoria B.C. anawim house\n",
            "Found 0 submissions for term 'Victoria B.C. anawim house' in subreddit 'Sooke'\n",
            "Searching for term: oakbaynews\n",
            "Found 0 submissions for term 'oakbaynews' in subreddit 'Sooke'\n",
            "Searching for term: barclaywallace\n",
            "Found 0 submissions for term 'barclaywallace' in subreddit 'Sooke'\n",
            "Searching for term: rotary club of victoria\n",
            "Found 1 submissions for term 'rotary club of victoria' in subreddit 'Sooke'\n",
            "Processing submission: 3kcf1n\n",
            "Searching for term: YYJ anawim house\n",
            "Found 0 submissions for term 'YYJ anawim house' in subreddit 'Sooke'\n",
            "Searching for term: malahat bc housing\n",
            "Found 0 submissions for term 'malahat bc housing' in subreddit 'Sooke'\n",
            "Searching for term: malahat avi\n",
            "Found 0 submissions for term 'malahat avi' in subreddit 'Sooke'\n",
            "Searching for term: sarahpottsvic beacon community services\n",
            "Found 0 submissions for term 'sarahpottsvic beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: salt spring island\n",
            "Found 1 submissions for term 'salt spring island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Searching for term: emergency housing\n",
            "Found 0 submissions for term 'emergency housing' in subreddit 'Sooke'\n",
            "Searching for term: nuu-chah-nulth aids vancouver island\n",
            "Found 3 submissions for term 'nuu-chah-nulth aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: t'sou-ke beacon community services\n",
            "Found 0 submissions for term 't'sou-ke beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: colinplant2018\n",
            "Found 0 submissions for term 'colinplant2018' in subreddit 'Sooke'\n",
            "Searching for term: service provider\n",
            "Found 0 submissions for term 'service provider' in subreddit 'Sooke'\n",
            "Searching for term: the cridge centre for the family\n",
            "Found 0 submissions for term 'the cridge centre for the family' in subreddit 'Sooke'\n",
            "Searching for term: vfamcourt avi\n",
            "Found 0 submissions for term 'vfamcourt avi' in subreddit 'Sooke'\n",
            "Searching for term: housesooke\n",
            "Found 0 submissions for term 'housesooke' in subreddit 'Sooke'\n",
            "Searching for term: Camping\n",
            "Found 1 submissions for term 'Camping' in subreddit 'Sooke'\n",
            "Processing submission: m59ist\n",
            "Searching for term: quadravillage\n",
            "Found 0 submissions for term 'quadravillage' in subreddit 'Sooke'\n",
            "Searching for term: Poor \n",
            "Found 0 submissions for term 'Poor ' in subreddit 'Sooke'\n",
            "Searching for term: rockheights\n",
            "Found 0 submissions for term 'rockheights' in subreddit 'Sooke'\n",
            "Searching for term: saanichnews\n",
            "Found 0 submissions for term 'saanichnews' in subreddit 'Sooke'\n",
            "Searching for term: Eviction\n",
            "Found 0 submissions for term 'Eviction' in subreddit 'Sooke'\n",
            "Searching for term: the mustard seed\n",
            "Found 0 submissions for term 'the mustard seed' in subreddit 'Sooke'\n",
            "Searching for term: povertypimps\n",
            "Found 0 submissions for term 'povertypimps' in subreddit 'Sooke'\n",
            "Searching for term: alanrycroft aryze developments\n",
            "Found 0 submissions for term 'alanrycroft aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: workingupstream\n",
            "Found 0 submissions for term 'workingupstream' in subreddit 'Sooke'\n",
            "Searching for term: sarahpottsvic aids vancouver island\n",
            "Found 3 submissions for term 'sarahpottsvic aids vancouver island' in subreddit 'Sooke'\n",
            "Processing submission: t61vrr\n",
            "Processing submission: p00u2m\n",
            "Processing submission: 4ti4yn\n",
            "Searching for term: sooke homelessness coalition\n",
            "Found 0 submissions for term 'sooke homelessness coalition' in subreddit 'Sooke'\n",
            "Searching for term: barbdesjardins\n",
            "Found 0 submissions for term 'barbdesjardins' in subreddit 'Sooke'\n",
            "Searching for term: burnsidegorge avi\n",
            "Found 0 submissions for term 'burnsidegorge avi' in subreddit 'Sooke'\n",
            "Searching for term: ctvnewsvi\n",
            "Found 0 submissions for term 'ctvnewsvi' in subreddit 'Sooke'\n",
            "Searching for term: need_2\n",
            "Found 0 submissions for term 'need_2' in subreddit 'Sooke'\n",
            "Searching for term: Society of St Vincent De Paul\n",
            "Found 0 submissions for term 'Society of St Vincent De Paul' in subreddit 'Sooke'\n",
            "Searching for term: kristaloughton\n",
            "Found 0 submissions for term 'kristaloughton' in subreddit 'Sooke'\n",
            "Searching for term: Sooke Transition House Society\n",
            "Found 5 submissions for term 'Sooke Transition House Society' in subreddit 'Sooke'\n",
            "Processing submission: t98a89\n",
            "Processing submission: mw6cun\n",
            "Processing submission: 71lbrd\n",
            "Processing submission: lms4ms\n",
            "Processing submission: 44ukwu\n",
            "Searching for term: fernwoodfca\n",
            "Found 0 submissions for term 'fernwoodfca' in subreddit 'Sooke'\n",
            "Searching for term: salvation army victoria\n",
            "Found 0 submissions for term 'salvation army victoria' in subreddit 'Sooke'\n",
            "Searching for term: tsartlip boys \"and\" girls club south vanouver island\n",
            "Found 0 submissions for term 'tsartlip boys \"and\" girls club south vanouver island' in subreddit 'Sooke'\n",
            "Searching for term: burnsidegorge aceh\n",
            "Found 0 submissions for term 'burnsidegorge aceh' in subreddit 'Sooke'\n",
            "Searching for term: uvic beacon community services\n",
            "Found 0 submissions for term 'uvic beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: tseycum aryze developments\n",
            "Found 0 submissions for term 'tseycum aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: victorianews beacon community services\n",
            "Found 0 submissions for term 'victorianews beacon community services' in subreddit 'Sooke'\n",
            "Searching for term: rock bay\n",
            "Found 0 submissions for term 'rock bay' in subreddit 'Sooke'\n",
            "Searching for term: pauquachin aryze developments\n",
            "Found 0 submissions for term 'pauquachin aryze developments' in subreddit 'Sooke'\n",
            "Searching for term: vicyouthcouncil\n",
            "Found 0 submissions for term 'vicyouthcouncil' in subreddit 'Sooke'\n",
            "Searching for term: tent\n",
            "Found 1 submissions for term 'tent' in subreddit 'Sooke'\n",
            "Processing submission: m59ist\n",
            "Searching for term: housing\n",
            "Found 5 submissions for term 'housing' in subreddit 'Sooke'\n",
            "Processing submission: 71lbrd\n",
            "Processing submission: lms4ms\n",
            "Processing submission: mw6cun\n",
            "Processing submission: t98a89\n",
            "Processing submission: 44ukwu\n",
            "Searching for term: mustardseedvic bc housing\n",
            "Found 0 submissions for term 'mustardseedvic bc housing' in subreddit 'Sooke'\n",
            "Searching for term: Person experiencing homelessness \n",
            "Found 0 submissions for term 'Person experiencing homelessness ' in subreddit 'Sooke'\n",
            "Searching for term: Victoria Sexual Assault Centre\n",
            "Found 1 submissions for term 'Victoria Sexual Assault Centre' in subreddit 'Sooke'\n",
            "Processing submission: p00u2m\n",
            "Searching for term: Substance use\n",
            "Found 0 submissions for term 'Substance use' in subreddit 'Sooke'\n",
            "Searching for term: photowarrior boys \"and\" girls club south vanouver island\n",
            "Found 0 submissions for term 'photowarrior boys \"and\" girls club south vanouver island' in subreddit 'Sooke'\n",
            "Searching for term: songheeschief\n",
            "Found 0 submissions for term 'songheeschief' in subreddit 'Sooke'\n",
            "Searching for term: greater victoria housing society\n",
            "Found 2 submissions for term 'greater victoria housing society' in subreddit 'Sooke'\n",
            "Processing submission: 7w5qhj\n",
            "Processing submission: t98a89\n",
            "Searching for term: saanichpolice\n",
            "Found 0 submissions for term 'saanichpolice' in subreddit 'Sooke'\n",
            "Searching for term: brucealready avi\n",
            "Found 0 submissions for term 'brucealready avi' in subreddit 'Sooke'\n",
            "Searching for term: pauquachin bc housing\n",
            "Found 0 submissions for term 'pauquachin bc housing' in subreddit 'Sooke'\n",
            "Searching for term: Affordable\n",
            "Found 1 submissions for term 'Affordable' in subreddit 'Sooke'\n",
            "Processing submission: 71lbrd\n",
            "Searching for term: nuu-chah-nulth the aboriginal coalition to end homelessness\n",
            "Found 0 submissions for term 'nuu-chah-nulth the aboriginal coalition to end homelessness' in subreddit 'Sooke'\n",
            "Searching for term: pacificahousing\n",
            "Found 0 submissions for term 'pacificahousing' in subreddit 'Sooke'\n",
            "Searching for term: victoriadra aceh\n",
            "Found 0 submissions for term 'victoriadra aceh' in subreddit 'Sooke'\n",
            "Searching for term: sarahpottsvic aceh\n",
            "Found 0 submissions for term 'sarahpottsvic aceh' in subreddit 'Sooke'\n",
            "Searching for term: beaconsave\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-2e38be16aa76>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Run the main function and get the DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mreddit_data_search_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# Save the DataFrame to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Path to the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-2e38be16aa76>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mfetch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreddit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubreddits_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_terms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mawait\u001b[0m \u001b[0mreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-743a514942b1>\u001b[0m in \u001b[0;36mfetch_data\u001b[0;34m(reddit, subreddit_names, search_terms, limit_num)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Searching for term: {search_term}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0msubmissions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32masync\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubmission\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0msubmissions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found {len(submissions)} submissions for term '{search_term}' in subreddit '{subreddit_name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/models/listing/generator.py\u001b[0m in \u001b[0;36m__anext__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/models/listing/generator.py\u001b[0m in \u001b[0;36m_next_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mStopAsyncIteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reddit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_sublist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_listing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_list_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/util/deprecate_args.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/reddit.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, path, params)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \"\"\"\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objectify_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_deprecate_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fullnames\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"subreddits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/reddit.py\u001b[0m in \u001b[0;36m_objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[1;32m    566\u001b[0m         return self._objector.objectify(\n\u001b[0;32m--> 567\u001b[0;31m             await self.request(\n\u001b[0m\u001b[1;32m    568\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/util/deprecate_args.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0m_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncpraw/reddit.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mClientException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At most one of 'data' or 'json' is supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             return await self._core.request(\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncprawcore/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, path, data, files, json, params, timeout)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"api_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moauth_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         return await self._request_with_retries(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncprawcore/sessions.py\u001b[0m in \u001b[0;36m_request_with_retries\u001b[0;34m(self, data, json, method, params, timeout, url, retry_strategy_state)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0mretry_strategy_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         response, saved_exception = await self._make_request(\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncprawcore/sessions.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, data, json, method, params, retry_strategy_state, timeout, url)\u001b[0m\n\u001b[1;32m    185\u001b[0m     ):\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             response = await self._rate_limiter.call(\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requestor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_header_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncprawcore/rate_limit.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mset_header_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mrequest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/asyncprawcore/requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;34m\"\"\"Issue the HTTP request capturing any errors that may occur.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             return await self._http.request(\n\u001b[0m\u001b[1;32m     65\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/aiohttp/client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, proxy_headers, trace_request_ctx, read_bufsize)\u001b[0m\n\u001b[1;32m    584\u001b[0m                             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                                 \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                                 \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/aiohttp/client_reqrep.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, connection)\u001b[0m\n\u001b[1;32m    903\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protocol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m                     \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[union-attr]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHttpProcessingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m                     raise ClientResponseError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/aiohttp/streams.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m                 \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCancelledError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_waiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt-get install git-lfs"
      ],
      "metadata": {
        "id": "Bcnqm7sp-rkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git lfs track 'data/reddit_data_search_terms.csv'"
      ],
      "metadata": {
        "id": "5F6u7Uye-vFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git add .gitattributes 'data/reddit_data_search_terms.csv'\n",
        "# !git commit -m \"Add large CSV file with Git LFS\"\n",
        "\n",
        "# repo_url = 'https://github.com/alex-jk/SWB-GVCEH.git'  # Replace with your repository's URL\n",
        "# repo_url_with_token = repo_url[:8] + pat + \"@\" + repo_url[8:]\n",
        "# !git remote set-url origin {repo_url_with_token}\n",
        "\n",
        "# !git push origin main"
      ],
      "metadata": {
        "id": "-XVNG8Eu-yyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !git filter-branch --force --index-filter \\\n",
        "#   \"git rm --cached --ignore-unmatch data/reddit_data_search_terms.csv\" \\\n",
        "#   --prune-empty --tag-name-filter cat -- --all\n",
        "# !git push origin main --force\n"
      ],
      "metadata": {
        "id": "DQk7GVtk_Kj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load reddit data file\n",
        "##### Since the file is too large to be pushed to the git repo, it was uploaded to Google drive"
      ],
      "metadata": {
        "id": "weyYVg4RDYGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWW5IDBQlRFE",
        "outputId": "b9612039-578a-4ab8-f859-3750d5464cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/SWB-GVCEH/reddit_data_search_terms.csv'  # Update with the path to your CSV file in Google Drive\n",
        "reddit_data_search_df = pd.read_csv(file_path)\n",
        "print(reddit_data_search_df.shape)\n",
        "print(reddit_data_search_df.columns)\n",
        "print(reddit_data_search_df.head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbIhMF-oDaMd",
        "outputId": "4a97cba6-6341-428f-95b5-a6fc9b22f3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(159128, 5)\n",
            "Index(['Subreddit', 'Title', 'Text', 'User ID', 'Comment'], dtype='object')\n",
            "   Subreddit                                              Title  \\\n",
            "0      Sooke                                   Camping in Sooke   \n",
            "1      Sooke                                   Camping in Sooke   \n",
            "2      Sooke                                   Camping in Sooke   \n",
            "3      Sooke                                   Camping in Sooke   \n",
            "4      Sooke  Sooke boy denied $19,000 per month drug for th...   \n",
            "5      Sooke        Are power outages in Sooke a regular thing?   \n",
            "6      Sooke        Are power outages in Sooke a regular thing?   \n",
            "7      Sooke        Are power outages in Sooke a regular thing?   \n",
            "8      Sooke        Are power outages in Sooke a regular thing?   \n",
            "9      Sooke        Are power outages in Sooke a regular thing?   \n",
            "10     Sooke  Help: What’s the best option for housing right...   \n",
            "11     Sooke  Help: What’s the best option for housing right...   \n",
            "12     Sooke  Help: What’s the best option for housing right...   \n",
            "13     Sooke  Sooke Tourism Association: “Time to show off y...   \n",
            "14     Sooke  Cockatoo escaped across from Saseenos. Please ...   \n",
            "15     Sooke  Cockatoo escaped across from Saseenos. Please ...   \n",
            "16     Sooke  Sooke Tourism Association: “Time to show off y...   \n",
            "17     Sooke  Sooke Tourism Association: “Time to show off y...   \n",
            "18     Sooke  Help: What’s the best option for housing right...   \n",
            "19     Sooke  Help: What’s the best option for housing right...   \n",
            "\n",
            "                                                 Text         User ID  \\\n",
            "0   Hi, we’re planning on camping in Sooke on Apri...    VanillaWrong   \n",
            "1   Hi, we’re planning on camping in Sooke on Apri...    VanillaWrong   \n",
            "2   Hi, we’re planning on camping in Sooke on Apri...    VanillaWrong   \n",
            "3   Hi, we’re planning on camping in Sooke on Apri...    VanillaWrong   \n",
            "4                                                 NaN  TrueNorthGreen   \n",
            "5   Greetings, people of Sooke!\\nMy wife and I are...         Pkard82   \n",
            "6   Greetings, people of Sooke!\\nMy wife and I are...         Pkard82   \n",
            "7   Greetings, people of Sooke!\\nMy wife and I are...         Pkard82   \n",
            "8   Greetings, people of Sooke!\\nMy wife and I are...         Pkard82   \n",
            "9   Greetings, people of Sooke!\\nMy wife and I are...         Pkard82   \n",
            "10  Looking for at least a two bedroom, preferably...     redd_planet   \n",
            "11  Looking for at least a two bedroom, preferably...     redd_planet   \n",
            "12  Looking for at least a two bedroom, preferably...     redd_planet   \n",
            "13                                                NaN     AMadcapLass   \n",
            "14  3 days ago my friends cockatoo escaped from he...        babetteq   \n",
            "15  3 days ago my friends cockatoo escaped from he...        babetteq   \n",
            "16                                                NaN     AMadcapLass   \n",
            "17                                                NaN     AMadcapLass   \n",
            "18  Looking for at least a two bedroom, preferably...     redd_planet   \n",
            "19  Looking for at least a two bedroom, preferably...     redd_planet   \n",
            "\n",
            "                                              Comment  \n",
            "0   Check on the BC parks website to see if China ...  \n",
            "1   Just a heads up that there is a government man...  \n",
            "2   Check on the BC parks website to see if China ...  \n",
            "3   Just a heads up that there is a government man...  \n",
            "4   there are other treatments for this, i'm just ...  \n",
            "5   Lived here for a year. The power has probably ...  \n",
            "6   It depends where you’re at. In Sooke core, sun...  \n",
            "7   Yes, expect your power to go out several times...  \n",
            "8   Ah that's all good to know! Kinda what I'd exp...  \n",
            "9   Summer it’s rare, winter months it’s very common.  \n",
            "10  About the same options for those of us already...  \n",
            "11                                          [deleted]  \n",
            "12  Its better to buy than rent if you can afford ...  \n",
            "13  Would you post an address and contact phone nu...  \n",
            "14     I'll keep my eyes and ears open; best of luck!  \n",
            "15  Thank you.  Today was first of no sightings. W...  \n",
            "16  Would you post an address and contact phone nu...  \n",
            "17  Would you post an address and contact phone nu...  \n",
            "18  About the same options for those of us already...  \n",
            "19                                          [deleted]  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to concatenate title, text, and comments\n",
        "def concatenate_post_data(group):\n",
        "    # Concatenate the title and text\n",
        "    title_text = group['Title'].iloc[0] + ' ' + group['Text'].iloc[0]\n",
        "\n",
        "    # Concatenate all comments\n",
        "    comments = ' '.join(group['Comment'].astype(str))\n",
        "\n",
        "    # Full document (title, text, and comments)\n",
        "    full_document = title_text + ' ' + comments\n",
        "\n",
        "    return pd.Series([title_text, full_document], index=['TitleText', 'Document'])\n",
        "\n",
        "# Group by the post identifiers and apply the concatenation function\n",
        "grouped = reddit_data_search_df.groupby(['Subreddit', 'Title', 'Text', 'User ID'])\n",
        "documents_df = grouped.apply(concatenate_post_data).reset_index()\n",
        "\n",
        "# Displaying the first few rows\n",
        "print(documents_df.shape)\n",
        "print(documents_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "qlOqzVB67Krt",
        "outputId": "7032fcbb-5b83-432f-ba6d-74617eaf5e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3818, 6)\n",
            "  Subreddit                                              Title  \\\n",
            "0     Sooke        Are power outages in Sooke a regular thing?   \n",
            "1     Sooke  Are there sexual predator watchdog groups in S...   \n",
            "2     Sooke                                   Camping in Sooke   \n",
            "3     Sooke  Cockatoo escaped across from Saseenos. Please ...   \n",
            "4     Sooke  Help: What’s the best option for housing right...   \n",
            "\n",
            "                                                Text       User ID  \\\n",
            "0  Greetings, people of Sooke!\\nMy wife and I are...       Pkard82   \n",
            "1  My girlfriend was recently traveling on Vancou...  scoobysmokes   \n",
            "2  Hi, we’re planning on camping in Sooke on Apri...  VanillaWrong   \n",
            "3  3 days ago my friends cockatoo escaped from he...      babetteq   \n",
            "4  Looking for at least a two bedroom, preferably...   redd_planet   \n",
            "\n",
            "                                           TitleText  \\\n",
            "0  Are power outages in Sooke a regular thing? Gr...   \n",
            "1  Are there sexual predator watchdog groups in S...   \n",
            "2  Camping in Sooke Hi, we’re planning on camping...   \n",
            "3  Cockatoo escaped across from Saseenos. Please ...   \n",
            "4  Help: What’s the best option for housing right...   \n",
            "\n",
            "                                            Document  \n",
            "0  Are power outages in Sooke a regular thing? Gr...  \n",
            "1  Are there sexual predator watchdog groups in S...  \n",
            "2  Camping in Sooke Hi, we’re planning on camping...  \n",
            "3  Cockatoo escaped across from Saseenos. Please ...  \n",
            "4  Help: What’s the best option for housing right...  \n",
            "Data fetched and data/saved to reddit_documents_df.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d19ec9f-12fb-4e74-a0d0-574a938ccd12\", \"reddit_documents_df.csv\", 46414032)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpNFN6KB-xdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "documents_df.to_csv('/content/SWB-GVCEH/data/reddit_documents_df.csv', index=False)\n",
        "print(\"Data fetched and data/saved to reddit_documents_df.csv\")\n",
        "# Path to the CSV file\n",
        "file_path = '/content/SWB-GVCEH/data/reddit_documents_df.csv'\n",
        "# Trigger a download to your local machine\n",
        "files.download(file_path)"
      ],
      "metadata": {
        "id": "qBSZ-92Z-nFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your git remote URL to include the PAT for authentication\n",
        "repo_url = 'https://github.com/alex-jk/SWB-GVCEH.git'  # Replace with your repository's URL\n",
        "pat = os.environ['GITHUB_PAT']\n",
        "repo_url_with_token = repo_url[:8] + pat + \"@\" + repo_url[8:]\n",
        "\n",
        "!git remote set-url origin {repo_url_with_token}\n",
        "\n",
        "# Navigate to the repository directory, add, commit, and push the new CSV file\n",
        "%cd /content/SWB-GVCEH\n",
        "!git add 'data/reddit_documents_df.csv'\n",
        "!git commit -m \"Add fetched reddit_documents_df CSV\"\n",
        "!git push origin main  # Replace 'main' with your branch name if it's different\n",
        "\n",
        "# Reset the remote URL to the original without the PAT\n",
        "!git remote set-url origin {repo_url}\n",
        "print(\"CSV file pushed to GitHub.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plLLEvM39SCM",
        "outputId": "a825594b-e48a-4273-f25d-1e9cc5b64b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SWB-GVCEH\n",
            "[main baf7738] Add fetched reddit_documents_df CSV\n",
            " 1 file changed, 270673 insertions(+)\n",
            " create mode 100644 data/reddit_documents_df.csv\n",
            "Enumerating objects: 6, done.\n",
            "Counting objects: 100% (6/6), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (4/4), done.\n",
            "Writing objects: 100% (4/4), 8.77 MiB | 2.85 MiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/alex-jk/SWB-GVCEH.git\n",
            "   1ab4f04..baf7738  main -> main\n",
            "CSV file pushed to GitHub.\n"
          ]
        }
      ]
    }
  ]
}